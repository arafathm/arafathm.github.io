<!DOCTYPE html>
<html>

  <head>
    <meta charset="utf-8">
<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<meta http-equiv="X-UA-Compatible" content="IE=edge">

<title>M. Arafat  Hussain, PhD | publications</title>
<meta name="description" content="">

<!-- Open Graph -->


<!-- Bootstrap & MDB -->
<link href="https://stackpath.bootstrapcdn.com/bootstrap/4.5.2/css/bootstrap.min.css" rel="stylesheet" integrity="sha512-MoRNloxbStBcD8z3M/2BmnT+rg4IsMxPkXaGh2zD6LGNNFE80W3onsAhRcMAMrSoyWL9xD7Ert0men7vR8LUZg==" crossorigin="anonymous">
<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/mdbootstrap/4.19.1/css/mdb.min.css" integrity="sha512-RO38pBRxYH3SoOprtPTD86JFOclM51/XTIdEPh5j8sj4tp8jmQIx26twG52UaLi//hQldfrh7e51WzP9wuP32Q==" crossorigin="anonymous" />

<!-- Fonts & Icons -->
<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.14.0/css/all.min.css"  integrity="sha512-1PKOgIY59xJ8Co8+NE6FZ+LOAZKjy+KY8iq0G4B3CyeY6wYHN3yt9PW0XpSriVlkMXe40PTKnXrLnZ9+fkDaog==" crossorigin="anonymous">
<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/academicons/1.9.0/css/academicons.min.css" integrity="sha512-W4yqoT1+8NLkinBLBZko+dFB2ZbHsYLDdr50VElllRcNt2Q4/GSs6u71UHKxB7S6JEMCp5Ve4xjh3eGQl/HRvg==" crossorigin="anonymous">
<link rel="stylesheet" type="text/css" href="https://fonts.googleapis.com/css?family=Roboto:300,400,500,700|Roboto+Slab:100,300,400,500,700|Material+Icons">

<!-- Code Syntax Highlighting -->
<link rel="stylesheet" href="https://gitcdn.xyz/repo/jwarby/jekyll-pygments-themes/master/github.css" />

<!-- Styles -->

<link rel="icon" href="data:image/svg+xml,<svg xmlns=%22http://www.w3.org/2000/svg%22 viewBox=%220 0 100 100%22><text y=%22.9em%22 font-size=%2290%22>Ⓜ️</text></svg>">

<link rel="stylesheet" href="/assets/css/main.css">

<link rel="canonical" href="/publications/">

<!-- JQuery -->
<!-- jQuery -->
<script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.5.1/jquery.min.js" integrity="sha512-bLT0Qm9VnAYZDflyKcBaQ2gg0hSYNQrJ8RilYldYQ1FxQYoCLtUjuuRuZo+fjqhx/qtq/1itJ0C2ejDxltZVFg==" crossorigin="anonymous"></script>


<!-- Theming-->






    
<!-- MathJax -->
<script type="text/javascript">
  window.MathJax = {
    tex: {
      tags: 'ams'
    }
  };
</script>
<script defer type="text/javascript" id="MathJax-script" src="https://cdn.jsdelivr.net/npm/mathjax@3.1.2/es5/tex-mml-chtml.js"></script>
<script defer src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>


  </head>

  <body class="fixed-top-nav ">

    <!-- Header -->

    <header>

    <!-- Nav Bar -->
    <nav id="navbar" class="navbar navbar-light navbar-expand-sm fixed-top">
    <div class="container">
      
      <a class="navbar-brand title font-weight-lighter" href="/">
       <span class="font-weight-bold">M. Arafat</span>   Hussain, PhD
      </a>
      
      <!-- Navbar Toggle -->
      <button class="navbar-toggler collapsed ml-auto" type="button" data-toggle="collapse" data-target="#navbarNav" aria-controls="navbarNav" aria-expanded="false" aria-label="Toggle navigation">
        <span class="sr-only">Toggle navigation</span>
        <span class="icon-bar top-bar"></span>
        <span class="icon-bar middle-bar"></span>
        <span class="icon-bar bottom-bar"></span>
      </button>
      <div class="collapse navbar-collapse text-right" id="navbarNav">
        <ul class="navbar-nav ml-auto flex-nowrap">
          <!-- About -->
          <li class="nav-item ">
            <a class="nav-link" href="/">
              about
              
            </a>
          </li>
          
          <!-- Other pages -->
          
          
          
          
          
          
          
          
          
          
          
          
          
          
          
          <li class="nav-item ">
              <a class="nav-link" href="/cv/">
                cv
                
              </a>
          </li>
          
          
          
          <li class="nav-item active">
              <a class="nav-link" href="/publications/">
                publications
                
                <span class="sr-only">(current)</span>
                
              </a>
          </li>
          
          
          
          <li class="nav-item ">
              <a class="nav-link" href="/research/">
                research
                
              </a>
          </li>
          
          
          
          <li class="nav-item ">
              <a class="nav-link" href="/teaching/">
                teaching
                
              </a>
          </li>
          
          
          
        </ul>
      </div>
    </div>
  </nav>

</header>


    <!-- Content -->

    <div class="container mt-5">
      <div class="post">

  <header class="post-header">
    <h1 class="post-title">publications</h1>
    <p class="post-description"><span>*</span> Denotes equal contribution and joint lead authorship. Please see my <a href="https://scholar.google.ca/citations?user=hFwvdQcAAAAJ&hl=en">Google Scholar</a> profile.</p>
  </header>

  <article>
    <div class="publications">


  <h2 class="year">2021</h2>
  <ol class="bibliography"><li><div class="row">
  <div class="col-sm-2 abbr">
  
    
    <abbr class="badge">CIBM</abbr>
    
  
  </div>

  <div id="momeny2021learning" class="col-sm-8">
    
      <div class="title">Learning-to-Augment Strategy using Noisy and Denoised Data: Improving Generalizability of Deep CNN for the Detection of COVID-19 in X-ray Images</div>
      <div class="author">
        
          
          
          
          
          
          
            
              
                
                  Momeny, Mohammad,
                
              
            
          
        
          
          
          
          
          
          
            
              
                
                  Neshat, Ali Asghar,
                
              
            
          
        
          
          
          
          
          
          
            
              
                <em>Hussain, Mohammad Arafat</em>,
              
            
          
        
          
          
          
          
          
          
            
              
                
                  Kia, Solmaz,
                
              
            
          
        
          
          
          
          
          
          
            
              
                
                  Marhamati, Mahmoud,
                
              
            
          
        
          
          
          
          
          
          
            
              
                
                  Jahanbakhshi, Ahmad,
                
              
            
          
        
          
          
          
          
            
              
                
                
          
          
          
            
              
                
                  and <a href="https://www.sfu.ca/computing/people/faculty/ghassanhamarneh.html" target="_blank">Hamarneh, Ghassan</a>
                
              
            
          
        
      </div>

      <div class="periodical">
      
        <em>Computers in Biology and Medicine</em>
      
      
        2021
      
      </div>
    

    <div class="links">
    
      <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a>
    
    
    
      <a href="https://www.sciencedirect.com/science/article/abs/pii/S0010482521004984" class="btn btn-sm z-depth-0" role="button" target="_blank">HTML</a>
    
    
      
      <a href="/assets/pdf/cibm2021.pdf" class="btn btn-sm z-depth-0" role="button" target="_blank">PDF</a>
      
    
    
    
    
      <a href="https://github.com/mohamadmomeny/Learning-to-augment-strategy" class="btn btn-sm z-depth-0" role="button" target="_blank">Code</a>
    
    
    
    
    </div>

    <!-- Hidden abstract block -->
    
    <div class="abstract hidden">
      <p>Chest X-ray images are used in deep convolutional neural networks for the detection of COVID-19, the greatest human challenge of the 21st century. Robustness to noise and improvement of generalization are the major challenges in designing these networks. In this paper, we introduce a strategy for data augmentation using the determination of the type and value of noise density to improve the robustness and generalization of deep CNNs for COVID-19 detection. Firstly, we present a learning-to-augment approach that generates new noisy variants of the original image data with optimized noise density. We apply a Bayesian optimization technique to control and choose the optimal noise type and its parameters. Secondly, we propose a novel data augmentation strategy, based on denoised X-ray images, that uses the distance between denoised and original pixels to generate new data. We develop an autoencoder model to create new data using denoised images corrupted by the Gaussian and impulse noise. A database of chest X-ray images, containing COVID-19 positive images, normal images, and other non-COVID pneumonia images, is used to fine-tune the pre-trained networks (AlexNet, ShuffleNet, ResNet18, and GoogleNet). The proposed method has the better performance in comparison with the data augmentation approaches in terms of sensitivity (by 0.808), specificity (by 0.915), and F-Measure (by 0.737).</p>
    </div>
    
  </div>
</div>
</li>
<li><div class="row">
  <div class="col-sm-2 abbr">
  
    
    <abbr class="badge">CMIG</abbr>
    
  
  </div>

  <div id="hussain2021learnable" class="col-sm-8">
    
      <div class="title">Learnable Image Histograms-based Deep Radiomics for Renal Cell Carcinoma Grading and Staging</div>
      <div class="author">
        
          
          
          
          
          
          
            
              
                <em>Hussain, Mohammad Arafat</em>,
              
            
          
        
          
          
          
          
            
              
                
                
          
          
          
            
              
                
                  <a href="https://www.sfu.ca/computing/people/faculty/ghassanhamarneh.html" target="_blank">Hamarneh, Ghassan</a>,
                
              
            
          
        
          
          
          
          
            
              
                
                
          
          
          
            
              
                
                  and <a href="https://bisicl.ece.ubc.ca/rafeef/" target="_blank">Garbi, Rafeef</a>
                
              
            
          
        
      </div>

      <div class="periodical">
      
        <em>Computerized Medical Imaging and Graphics</em>
      
      
        2021
      
      </div>
    

    <div class="links">
    
      <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a>
    
    
    
      <a href="https://www.sciencedirect.com/science/article/abs/pii/S0895611121000732" class="btn btn-sm z-depth-0" role="button" target="_blank">HTML</a>
    
    
      
      <a href="/assets/pdf/cmig_arafat_2021.pdf" class="btn btn-sm z-depth-0" role="button" target="_blank">PDF</a>
      
    
    
    
    
      <a href="https://github.com/marafathussain/ImHistNet" class="btn btn-sm z-depth-0" role="button" target="_blank">Code</a>
    
    
    
    
    </div>

    <!-- Hidden abstract block -->
    
    <div class="abstract hidden">
      <p>Fuhrman cancer grading and tumor-node-metastasis (TNM) cancer staging systems are typically used by clinicians in the treatment planning of renal cell carcinoma (RCC), a common cancer in men and women worldwide. Pathologists typically use percutaneous renal biopsy for RCC grading, while staging is performed by volumetric medical image analysis before renal surgery. Recent studies suggest that clinicians can effectively perform these classification tasks non-invasively by analysing image texture features of RCC from computed tomography (CT) data. However, image feature identification for RCC grading and staging often relies on laborious manual processes, which is error prone and time-intensive. To address this challenge, this paper proposes a learnable image histogram in the deep neural network framework that can learn task-specific image histograms with variable bin centers and widths. The proposed approach enables learning statistical context features from raw medical data, which cannot be performed by a conventional convolutional neural network (CNN). The linear basis function of our learnable image histogram is piece-wise differentiable, enabling back-propagating errors to update the variable bin centers and widths during training. This novel approach can segregate the CT textures of an RCC in different intensity spectra, which enables effcient Fuhrman low (I/II) and high (III/IV) grading as well as RCC low (I/II) and high (III/IV) staging. The proposed method is validated on a clinical CT dataset of 159 patients from The Cancer Imaging Archive (TCIA) database, and it demonstrates 80% and 83% accuracy in RCC grading and staging, respectively.</p>
    </div>
    
  </div>
</div>
</li>
<li><div class="row">
  <div class="col-sm-2 abbr">
  
    
    <abbr class="badge">IEEE TMI</abbr>
    
  
  </div>

  <div id="hussain2021cascaded" class="col-sm-8">
    
      <div class="title">Cascaded Localization Regression Neural Nets for Kidney Localization and Segmentation-free Volume Estimation</div>
      <div class="author">
        
          
          
          
          
          
          
            
              
                <em>Hussain, Mohammad Arafat</em>,
              
            
          
        
          
          
          
          
            
              
                
                
          
          
          
            
              
                
                  <a href="https://www.sfu.ca/computing/people/faculty/ghassanhamarneh.html" target="_blank">Hamarneh, Ghassan</a>,
                
              
            
          
        
          
          
          
          
            
              
                
                
          
          
          
            
              
                
                  and <a href="https://bisicl.ece.ubc.ca/rafeef/" target="_blank">Garbi, Rafeef</a>
                
              
            
          
        
      </div>

      <div class="periodical">
      
        <em>IEEE Transactions on Medical Imaging</em>
      
      
        2021
      
      </div>
    

    <div class="links">
    
      <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a>
    
    
    
      <a href="https://ieeexplore.ieee.org/abstract/document/9358223?casa_token=rxZNi4GaP-YAAAAA:vlaAvOf6J1pKBT9goM4k0cCgPyJQ9NgOg_SSzt4iAFwHINOSelv-LsPXU44-XYmkME_wsI8" class="btn btn-sm z-depth-0" role="button" target="_blank">HTML</a>
    
    
      
      <a href="/assets/pdf/tmi2021.pdf" class="btn btn-sm z-depth-0" role="button" target="_blank">PDF</a>
      
    
    
    
    
    
    
    
    </div>

    <!-- Hidden abstract block -->
    
    <div class="abstract hidden">
      <p>Kidney volume is an essential biomarker for a number of kidney disease diagnoses, for example, chronic kidney disease. Existing total kidney volume estimation methods often rely on an intermediate kidney segmentation step. On the other hand, automatic kidney localization in volumetric medical images is a critical step that often precedes subsequent data processing and analysis. Most current approaches perform kidney localization via an intermediate classification or regression step. This paper proposes an integrated deep learning approach for (i) kidney localization in computed tomography scans and (ii) segmentation-free renal volume estimation. Our localization method uses a selection-convolutional neural network that approximates the kidney inferior-superior span along the axial direction. Cross-sectional (2D) slices from the estimated span are subsequently used in a combined sagittal-axial Mask-RCNN that detects the organ bounding boxes on the axial and sagittal slices, the combination of which produces a final 3D organ bounding box. Furthermore, we use a fully convolutional network to estimate the kidney volume that skips the segmentation procedure. We also present a mathematical expression to approximate the ‘volume error’ metric from the ‘Sørensen–Dice coefficient.’ We accessed 100 patients’ CT scans from the Vancouver General Hospital records and obtained 210 patients’ CT scans from the 2019 Kidney Tumor Segmentation Challenge database to validate our method. Our method produces a kidney boundary wall localization error of  2.4mm and a mean volume estimation error of  5%.</p>
    </div>
    
  </div>
</div>
</li></ol>

  <h2 class="year">2020</h2>
  <ol class="bibliography"><li><div class="row">
  <div class="col-sm-2 abbr">
  
    
    <abbr class="badge">PhD Thesis</abbr>
    
  
  </div>

  <div id="hussain2020volumetric" class="col-sm-8">
    
      <div class="title">Volumetric image-based supervised learning approaches for kidney cancer detection and analysis</div>
      <div class="author">
        
          
          
          
          
          
          
            
              <em>Hussain, Mohammad Arafat</em>
            
          
        
      </div>

      <div class="periodical">
      
      
        2020
      
      </div>
    

    <div class="links">
    
    
    
      <a href="https://open.library.ubc.ca/cIRcle/collections/ubctheses/24/items/1.0389786" class="btn btn-sm z-depth-0" role="button" target="_blank">HTML</a>
    
    
      
      <a href="https://open.library.ubc.ca/media/download/pdf/24/1.0389786/4" class="btn btn-sm z-depth-0" role="button" target="_blank">PDF</a>
      
    
    
    
    
    
    
    
    </div>

    <!-- Hidden abstract block -->
    
  </div>
</div>
</li></ol>

  <h2 class="year">2019</h2>
  <ol class="bibliography"><li><div class="row">
  <div class="col-sm-2 abbr">
  
    
    <abbr class="badge">MICCAI</abbr>
    
  
  </div>

  <div id="hussain2019imhistnet" class="col-sm-8">
    
      <div class="title">ImHistNet: Learnable image histogram based DNN with application to noninvasive determination of carcinoma grades in CT scans</div>
      <div class="author">
        
          
          
          
          
          
          
            
              
                <em>Hussain, Mohammad Arafat</em>,
              
            
          
        
          
          
          
          
            
              
                
                
          
          
          
            
              
                
                  <a href="https://www.sfu.ca/computing/people/faculty/ghassanhamarneh.html" target="_blank">Hamarneh, Ghassan</a>,
                
              
            
          
        
          
          
          
          
            
              
                
                
          
          
          
            
              
                
                  and <a href="https://bisicl.ece.ubc.ca/rafeef/" target="_blank">Garbi, Rafeef</a>
                
              
            
          
        
      </div>

      <div class="periodical">
      
        <em>In International Conference on Medical Image Computing and Computer-Assisted Intervention</em>
      
      
        2019
      
      </div>
    

    <div class="links">
    
      <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a>
    
    
    
      <a href="https://link.springer.com/chapter/10.1007/978-3-030-32226-7_15" class="btn btn-sm z-depth-0" role="button" target="_blank">HTML</a>
    
    
      
      <a href="/assets/pdf/mahmiccai19.pdf" class="btn btn-sm z-depth-0" role="button" target="_blank">PDF</a>
      
    
    
    
    
      <a href="https://github.com/marafathussain/ImHistNet" class="btn btn-sm z-depth-0" role="button" target="_blank">Code</a>
    
    
    
    
    </div>

    <!-- Hidden abstract block -->
    
    <div class="abstract hidden">
      <p>Renal cell carcinoma (RCC) is the seventh most common cancer worldwide, accounting for an estimated 140,000 global deaths annually. Clear cell RCC (ccRCC) is the major subtype of RCC and its biological aggressiveness affects prognosis and treatment planning. An important ccRCC prognostic predictor is its ‘grade’ for which the 4-tiered Fuhrman grading system is used. Although the Fuhrman grade can be identified by percutaneous renal biopsy, recent studies suggested that such grades may be non-invasively identified by studying image texture features of the ccRCC from computed tomography (CT) data. Such image feature based identification currently mostly relies on laborious manual processes based on visual inspection of 2D image slices that are time-consuming and subjective. In this paper, we propose a learnable image histogram based deep neural network approach that can perform the Fuhrman low (I/II) and high (III/IV) grade classification for ccRCC in CT scans. Validated on a clinical CT dataset of 159 patients from the TCIA database, our method classified ccRCC low and high grades with 80% accuracy and 85% AUC.</p>
    </div>
    
  </div>
</div>
</li>
<li><div class="row">
  <div class="col-sm-2 abbr">
  
    
    <abbr class="badge">MICCAI-MLMI</abbr>
    
  
  </div>

  <div id="hussain2019renal" class="col-sm-8">
    
      <div class="title">Renal Cell Carcinoma Staging with Learnable Image Histogram-Based Deep Neural Network</div>
      <div class="author">
        
          
          
          
          
          
          
            
              
                <em>Hussain, Mohammad Arafat</em>,
              
            
          
        
          
          
          
          
            
              
                
                
          
          
          
            
              
                
                  <a href="https://www.sfu.ca/computing/people/faculty/ghassanhamarneh.html" target="_blank">Hamarneh, Ghassan</a>,
                
              
            
          
        
          
          
          
          
            
              
                
                
          
          
          
            
              
                
                  and <a href="https://bisicl.ece.ubc.ca/rafeef/" target="_blank">Garbi, Rafeef</a>
                
              
            
          
        
      </div>

      <div class="periodical">
      
        <em>In International Workshop on Machine Learning in Medical Imaging</em>
      
      
        2019
      
      </div>
    

    <div class="links">
    
      <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a>
    
    
    
      <a href="https://link.springer.com/chapter/10.1007/978-3-030-32692-0_61" class="btn btn-sm z-depth-0" role="button" target="_blank">HTML</a>
    
    
      
      <a href="/assets/pdf/mahmlmi19.pdf" class="btn btn-sm z-depth-0" role="button" target="_blank">PDF</a>
      
    
    
    
    
      <a href="https://github.com/marafathussain/ImHistNet" class="btn btn-sm z-depth-0" role="button" target="_blank">Code</a>
    
    
    
    
    </div>

    <!-- Hidden abstract block -->
    
    <div class="abstract hidden">
      <p>Renal cell carcinoma (RCC) is the seventh most common cancer worldwide, accounting for an estimated 140,000 global deaths annually. An important RCC prognostic predictor is its ‘stage’ for which the tumor-node-metastasis (TNM) staging system is used. Although TNM staging is performed by radiologists via pre-surgery volumetric medical image analysis, a recent study suggested that such staging may be performed by studying the image features of the RCC from computed tomography (CT) data. Currently TNM staging mostly relies on laborious manual processes based on visual inspection of 2D CT image slices that are time-consuming and subjective; a recent study reported about   ∼ 25% misclassification in their patient pools. Recently, we proposed a learnable image histogram based deep neural network approach (ImHistNet) for RCC grading, which is capable of learning textural features directly from the CT images. In this paper, using a similar architecture, we perform the stage low (I/II) and high (III/IV) classification for RCC in CT scans. Validated on a clinical CT dataset of 159 patients from the TCIA database, our method classified RCC low and high stages with about 83% accuracy.</p>
    </div>
    
  </div>
</div>
</li></ol>

  <h2 class="year">2018</h2>
  <ol class="bibliography"><li><div class="row">
  <div class="col-sm-2 abbr">
  
    
    <abbr class="badge">MICCAI</abbr>
    
  
  </div>

  <div id="hussain2018noninvasive" class="col-sm-8">
    
      <div class="title">Noninvasive determination of gene mutations in clear cell renal cell carcinoma using multiple instance decisions aggregated CNN</div>
      <div class="author">
        
          
          
          
          
          
          
            
              
                <em>Hussain, Mohammad Arafat</em>,
              
            
          
        
          
          
          
          
            
              
                
                
          
          
          
            
              
                
                  <a href="https://www.sfu.ca/computing/people/faculty/ghassanhamarneh.html" target="_blank">Hamarneh, Ghassan</a>,
                
              
            
          
        
          
          
          
          
            
              
                
                
          
          
          
            
              
                
                  and <a href="https://bisicl.ece.ubc.ca/rafeef/" target="_blank">Garbi, Rafeef</a>
                
              
            
          
        
      </div>

      <div class="periodical">
      
        <em>In International Conference on Medical Image Computing and Computer-Assisted Intervention</em>
      
      
        2018
      
      </div>
    

    <div class="links">
    
      <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a>
    
    
    
      <a href="https://link.springer.com/chapter/10.1007/978-3-030-00934-2_73" class="btn btn-sm z-depth-0" role="button" target="_blank">HTML</a>
    
    
      
      <a href="/assets/pdf/Arafat_MICCAI18.pdf" class="btn btn-sm z-depth-0" role="button" target="_blank">PDF</a>
      
    
    
    
    
    
    
    
    </div>

    <!-- Hidden abstract block -->
    
    <div class="abstract hidden">
      <p>Kidney clear cell renal cell carcinoma (ccRCC) is the major sub-type of RCC, constituting one the most common cancers worldwide accounting for a steadily increasing mortality rate with 350,000 new cases recorded in 2012. Understanding the underlying genetic mutations in ccRCC provides crucial information enabling malignancy staging and patient survival estimation thus plays a vital role in accurate ccRCC diagnosis, prognosis, treatment planning, and response assessment. Although the underlying gene mutations can be identified by whole genome sequencing of the ccRCC following invasive nephrectomy or kidney biopsy procedures, recent studies have suggested that such mutations may be noninvasively identified by studying image features of the ccRCC from Computed Tomography (CT) data. Such image feature identification currently relies on laborious manual processes based on visual inspection of 2D image slices that are time-consuming and subjective. In this paper, we propose a convolutional neural network approach for automatic detection of underlying ccRCC gene mutations from 3D CT volumes. We aggregate the mutation-presence/absence decisions for all the ccRCC slices in a kidney into a robust singular decision that determines whether the interrogated kidney bears a specific mutation or not. When validated on clinical CT datasets of 267 patients from the TCIA database, our method detected gene mutations with 94% accuracy.</p>
    </div>
    
  </div>
</div>
</li></ol>

  <h2 class="year">2017</h2>
  <ol class="bibliography"><li><div class="row">
  <div class="col-sm-2 abbr">
  
    
    <abbr class="badge">MICCAI</abbr>
    
  
  </div>

  <div id="hussain2017segmentation" class="col-sm-8">
    
      <div class="title">Segmentation-free kidney localization and volume estimation using aggregated orthogonal decision CNNs</div>
      <div class="author">
        
          
          
          
          
          
          
            
              
                <em>Hussain, Mohammad Arafat</em>,
              
            
          
        
          
          
          
          
          
          
            
              
                
                  Amir-Khalili, Alborz,
                
              
            
          
        
          
          
          
          
            
              
                
                
          
          
          
            
              
                
                  <a href="https://www.sfu.ca/computing/people/faculty/ghassanhamarneh.html" target="_blank">Hamarneh, Ghassan</a>,
                
              
            
          
        
          
          
          
          
            
              
                
                
          
          
          
            
              
                
                  and <a href="https://bisicl.ece.ubc.ca/rafeef/" target="_blank">Abugharbieh, Rafeef</a>
                
              
            
          
        
      </div>

      <div class="periodical">
      
        <em>In International Conference on Medical Image Computing and Computer-Assisted Intervention</em>
      
      
        2017
      
      </div>
    

    <div class="links">
    
      <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a>
    
    
    
      <a href="https://link.springer.com/chapter/10.1007/978-3-319-66179-7_70" class="btn btn-sm z-depth-0" role="button" target="_blank">HTML</a>
    
    
      
      <a href="/assets/pdf/Arafat_MICCAI17.pdf" class="btn btn-sm z-depth-0" role="button" target="_blank">PDF</a>
      
    
    
    
    
    
    
    
    </div>

    <!-- Hidden abstract block -->
    
    <div class="abstract hidden">
      <p>Kidney volume is an important bio-marker in the clinical diagnosis of various renal diseases. For example, it plays an essential role in follow-up evaluation of kidney transplants. Most existing methods for volume estimation rely on kidney segmentation as a prerequisite step, which has various limitations such as initialization-sensitivity and computationally-expensive optimization. In this paper, we propose a hybrid localization-volume estimation deep learning approach capable of (i) localizing kidneys in abdominal CT images, and (ii) estimating renal volume without requiring segmentation. Our approach involves multiple levels of self-learning of image representation using convolutional neural layers, which we show better capture the rich and complex variability in kidney data, demonstrably outperforming hand-crafted feature representations. We validate our method on clinical data of 100 patients with a total of 200 kidney samples (left and right). Our results demonstrate a 55% increase in kidney boundary localization accuracy, and a 30% increase in volume estimation accuracy compared to recent state-of-the-art methods deploying regression-forest-based learning for the same tasks.</p>
    </div>
    
  </div>
</div>
</li>
<li><div class="row">
  <div class="col-sm-2 abbr">
  
    
    <abbr class="badge">MICCAI-MLMI</abbr>
    
  
  </div>

  <div id="hussain2017collage" class="col-sm-8">
    
      <div class="title">Collage CNN for renal cell carcinoma detection from CT</div>
      <div class="author">
        
          
          
          
          
          
          
            
              
                <em>Hussain, Mohammad Arafat</em>,
              
            
          
        
          
          
          
          
          
          
            
              
                
                  Amir-Khalili, Alborz,
                
              
            
          
        
          
          
          
          
            
              
                
                
          
          
          
            
              
                
                  <a href="https://www.sfu.ca/computing/people/faculty/ghassanhamarneh.html" target="_blank">Hamarneh, Ghassan</a>,
                
              
            
          
        
          
          
          
          
            
              
                
                
          
          
          
            
              
                
                  and <a href="https://bisicl.ece.ubc.ca/rafeef/" target="_blank">Abugharbieh, Rafeef</a>
                
              
            
          
        
      </div>

      <div class="periodical">
      
        <em>In International Workshop on Machine Learning in Medical Imaging</em>
      
      
        2017
      
      </div>
    

    <div class="links">
    
      <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a>
    
    
    
      <a href="https://link.springer.com/chapter/10.1007/978-3-319-67389-9_27" class="btn btn-sm z-depth-0" role="button" target="_blank">HTML</a>
    
    
      
      <a href="/assets/pdf/Arafat_MLMI17.pdf" class="btn btn-sm z-depth-0" role="button" target="_blank">PDF</a>
      
    
    
    
    
    
    
    
    </div>

    <!-- Hidden abstract block -->
    
    <div class="abstract hidden">
      <p>Renal cell carcinoma (RCC) is a common malignancy that accounts for a steadily increasing mortality rate worldwide. Widespread use of abdominal imaging in recent years, mainly CT and MRI, has significantly increased the detection rates of such cancers. However, detection still relies on a laborious manual process based on visual inspection of 2D image slices. In this paper, we propose an image collage based deep convolutional neural network (CNN) approach for automatic detection of pathological kidneys containing RCC. Our collage approach overcomes the absence of slice-wise training labels, enables slice-reshuffling based data augmentation, and offers favourable training time and performance compared to 3D CNNs. When validated on clinical CT datasets of 160 patients from the TCIA database, our method classified RCC cases vs. normal kidneys with 98% accuracy.</p>
    </div>
    
  </div>
</div>
</li>
<li><div class="row">
  <div class="col-sm-2 abbr">
  
    
    <abbr class="badge">UMB</abbr>
    
  
  </div>

  <div id="hussain2017strain" class="col-sm-8">
    
      <div class="title">Strain-initialized robust bone surface detection in 3-D ultrasound</div>
      <div class="author">
        
          
          
          
          
          
          
            
              
                <em>Hussain, Mohammad Arafat</em>,
              
            
          
        
          
          
          
          
            
              
                
                
          
          
          
            
              
                
                  <a href="https://mech.ubc.ca/antony-hodgson/" target="_blank">Hodgson, Antony J</a>,
                
              
            
          
        
          
          
          
          
            
              
                
                
          
          
          
            
              
                
                  and <a href="https://bisicl.ece.ubc.ca/rafeef/" target="_blank">Abugharbieh, Rafeef</a>
                
              
            
          
        
      </div>

      <div class="periodical">
      
        <em>Ultrasound in medicine &amp; biology</em>
      
      
        2017
      
      </div>
    

    <div class="links">
    
      <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a>
    
    
    
      <a href="https://www.sciencedirect.com/science/article/pii/S0301562916303696?casa_token=krY2KlUluY8AAAAA:5y7hfrUvrHjJkcsVWHnUtw5g3Wa3KWuLRwL3oSu8Ggn6YjiCxEd166yYSrWmEingXL1H09FN" class="btn btn-sm z-depth-0" role="button" target="_blank">HTML</a>
    
    
      
      <a href="/assets/pdf/Arafat_UMB17.pdf" class="btn btn-sm z-depth-0" role="button" target="_blank">PDF</a>
      
    
    
    
    
    
    
    
    </div>

    <!-- Hidden abstract block -->
    
    <div class="abstract hidden">
      <p>Three-dimensional ultrasound has been increasingly considered as a safe radiation-free alternative to radiation-based fluoroscopic imaging for surgical guidance during computer-assisted orthopedic interventions, but because ultrasound images contain significant artifacts, it is challenging to automatically extract bone surfaces from these images. We propose an effective way to extract 3-D bone surfaces using a surface growing approach that is seeded from 2-D bone contours. The initial 2-D bone contours are estimated from a combination of ultrasound strain images and envelope power images. Novel features of the proposed method include: (i) improvement of a previously reported 2-D strain imaging-based bone segmentation method by incorporation of a depth-dependent cumulative power of the envelope into the elastographic data; (ii) incorporation of an echo decorrelation measure-based weight to fuse the strain and envelope maps; (iii) use of local statistics of the bone surface candidate points to detect the presence of any bone discontinuity; and (iv) an extension of our 2-D bone contour into a 3-D bone surface by use of an effective surface growing approach. Our new method produced average improvements in the mean absolute error of 18% and 23%, respectively, on 2-D and 3-D experimental phantom data, compared with those of two state-of-the-art bone segmentation methods. Validation on 2-D and 3-D clinical in vivo data also reveals, respectively, an average improvement in the mean absolute fitting error of 55% and an 18-fold improvement in the computation time.</p>
    </div>
    
  </div>
</div>
</li></ol>

  <h2 class="year">2016</h2>
  <ol class="bibliography"><li><div class="row">
  <div class="col-sm-2 abbr">
  
    
    <abbr class="badge">MICCAI-MLMI</abbr>
    
  
  </div>

  <div id="hussain2016segmentation" class="col-sm-8">
    
      <div class="title">Segmentation-free estimation of kidney volumes in CT with dual regression forests</div>
      <div class="author">
        
          
          
          
          
          
          
            
              
                <em>Hussain, Mohammad Arafat</em>,
              
            
          
        
          
          
          
          
            
              
                
                
          
          
          
            
              
                
                  <a href="https://www.sfu.ca/computing/people/faculty/ghassanhamarneh.html" target="_blank">Hamarneh, Ghassan</a>,
                
              
            
          
        
          
          
          
          
          
          
            
              
                
                  O’Connell, Timothy W,
                
              
            
          
        
          
          
          
          
          
          
            
              
                
                  Mohammed, Mohammed F,
                
              
            
          
        
          
          
          
          
            
              
                
                
          
          
          
            
              
                
                  and <a href="https://bisicl.ece.ubc.ca/rafeef/" target="_blank">Abugharbieh, Rafeef</a>
                
              
            
          
        
      </div>

      <div class="periodical">
      
        <em>In International Workshop on Machine Learning in Medical Imaging</em>
      
      
        2016
      
      </div>
    

    <div class="links">
    
      <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a>
    
    
    
      <a href="https://link.springer.com/chapter/10.1007/978-3-319-47157-0_19" class="btn btn-sm z-depth-0" role="button" target="_blank">HTML</a>
    
    
      
      <a href="/assets/pdf/MLMI2016.pdf" class="btn btn-sm z-depth-0" role="button" target="_blank">PDF</a>
      
    
    
    
    
    
    
    
    </div>

    <!-- Hidden abstract block -->
    
    <div class="abstract hidden">
      <p>Accurate estimation of kidney volume is essential for clinical diagnoses and therapeutic decisions related to renal diseases. Existing kidney volume estimation methods rely on an intermediate segmentation step that is subject to various limitations. In this work, we propose a segmentation-free, supervised learning approach that addresses the challenges of accurate kidney volume estimation caused by extensive variations in kidney shape, size and orientation across subjects. We develop dual regression forests to simultaneously predict the kidney area per image slice, and kidney span per image volume. We validate our method on a dataset of 45 subjects with a total of 90 kidney samples. We obtained a volume estimation accuracy higher than existing segmentation-free (by 72 %) and segmentation-based methods (by 82 %). Compared to a single regression model, the dual regression reduced the false positive area-estimates and improved volume estimation accuracy by 41 %. We also found a mean deviation of under 10 % between our estimated kidney volumes and those obtained manually by expert radiologists.</p>
    </div>
    
  </div>
</div>
</li></ol>

  <h2 class="year">2015</h2>
  <ol class="bibliography"><li><div class="row">
  <div class="col-sm-2 abbr">
  
    
    <abbr class="badge">ICEEE</abbr>
    
  
  </div>

  <div id="hussain2015compressively" class="col-sm-8">
    
      <div class="title">Compressively sensed ultrasound radio-frequency data reconstruction using the combined curvelets and wave atoms basis</div>
      <div class="author">
        
          
          
          
          
          
          
            
              
                <em>Hussain, Mohammad Arafat</em>,
              
            
          
        
          
          
          
          
          
          
            
              
                
                  and Shourov, Riad Mashrub
                
              
            
          
        
      </div>

      <div class="periodical">
      
        <em>In 2015 International Conference on Electrical &amp; Electronic Engineering (ICEEE)</em>
      
      
        2015
      
      </div>
    

    <div class="links">
    
      <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a>
    
    
    
      <a href="https://ieeexplore.ieee.org/abstract/document/7428257?casa_token=XICEk4II6TIAAAAA:g1EyVRJBif0dyvwfNNe9xHFZZvjfLYcwee5A-FKCcQvPHnkxzFUwhTN5IcmZzRowekltrJs" class="btn btn-sm z-depth-0" role="button" target="_blank">HTML</a>
    
    
      
      <a href="/assets/pdf/mah2015a.pdf" class="btn btn-sm z-depth-0" role="button" target="_blank">PDF</a>
      
    
    
    
    
    
    
    
    </div>

    <!-- Hidden abstract block -->
    
    <div class="abstract hidden">
      <p>In this paper, we propose a novel data reconstruction method for the compressively sensed ultrasound radio-frequency (RF) data using the combined curvelets- and wave atoms- (CCW) based orthonormal basis. Typically, the curvelets-based reconstruction better preserves the image features while the wave atoms-based reconstruction better preserves the oscillatory patterns of the typical ultrasound RF signals. We exploit the advantages from both the sparsifying bases via concatenating them where the RF reconstruction is done from the larger coefficients of the combined basis. We show that the CCW-based reconstruction method better recovers the RF oscillatory patterns as well as preserves the image features better than those of the curvelets- and wave atoms-based reconstruction methods alone. We find improvement with respect to the current methods of approximately 58% and 64% in terms of the normalized mean square error for the reconstructed synthetic phantom and in vivo RF data, respectively. We also show visual performance improvement in the B-mode images of approximately 33% and 44% in terms of the mean structural similarity for the synthetic phantom and in vivo data, respectively.</p>
    </div>
    
  </div>
</div>
</li>
<li><div class="row">
  <div class="col-sm-2 abbr">
  
    
    <abbr class="badge">ICCIT</abbr>
    
  
  </div>

  <div id="hussain2015towards" class="col-sm-8">
    
      <div class="title">Towards real-time 3D geometric nonlinear diffusion filter and its application to CT and MR imaging</div>
      <div class="author">
        
          
          
          
          
          
          
            
              
                <em>Hussain, Mohammad Arafat</em>,
              
            
          
        
          
          
          
          
          
          
            
              
                
                  Shourov, Riad Mashrub,
                
              
            
          
        
          
          
          
          
          
          
            
              
                
                  and Khan, Shamima Nasrin
                
              
            
          
        
      </div>

      <div class="periodical">
      
        <em>In 2015 18th International Conference on Computer and Information Technology (ICCIT)</em>
      
      
        2015
      
      </div>
    

    <div class="links">
    
      <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a>
    
    
    
      <a href="https://ieeexplore.ieee.org/abstract/document/7488115?casa_token=It1Pi7OtLEsAAAAA:F9bEARHP7syb_INZH1bJxrC_2RkyV4wyK1XJfNj4EvzUqFd9oVBAr8-9Nir8y-ad3ZusOa8" class="btn btn-sm z-depth-0" role="button" target="_blank">HTML</a>
    
    
      
      <a href="/assets/pdf/mah2015b.pdf" class="btn btn-sm z-depth-0" role="button" target="_blank">PDF</a>
      
    
    
    
    
    
    
    
    </div>

    <!-- Hidden abstract block -->
    
    <div class="abstract hidden">
      <p>We propose two near real-time nonlinear anisotropic diffusion filtering (NADF) methods for the 2D and 3D X-ray computed tomography (CT) and magnetic resonance (MR) image denoising. Typically, NADFs are preferred for the medical image denoising due to its edge preserving feature though they are computationally expensive. Recently, a computation-time efficient 2D NADF has been proposed which uses local pixel intensity-based geometric parameters for diffusion. But it has limitations resulting from (i) its assumption that the neighboring pixels are non-noisy while deciding on an interrogated pixel being noisy or not, and (ii) its confinement of working only on a 2D image. Motivated from this, we propose an improved 2D NADF method that uses additional neighboring pixels in an effective way to lower the noise impact on the estimated geometric parameters. We also extend our 2D method into 3D that considers all the three directions for information diffusion. The performance of the proposed methods is evaluated using a 3D synthetic phantom, and in vivo CT and MR data which demonstrates an average signal-to-noise-ratio-gain improvement of approximately 58% in 2D and 96% in 3D phantom data, and approximately 79% in 2D and 127% in 3D in vivo data, compared to the state-of-the-art method.</p>
    </div>
    
  </div>
</div>
</li>
<li><div class="row">
  <div class="col-sm-2 abbr">
  
    
    <abbr class="badge">CAOS</abbr>
    
  
  </div>

  <div id="hussain2015automatic" class="col-sm-8">
    
      <div class="title">Automatic Bone Segmentation in Ultrasound using Combined Ultrasound Strain Imaging and Envelope Signal Power</div>
      <div class="author">
        
          
          
          
          
          
          
            
              
                <em>Hussain, Mohammad Arafat</em>,
              
            
          
        
          
          
          
          
          
          
            
              
                
                  Guy, Pierre,
                
              
            
          
        
          
          
          
          
            
              
                
                
          
          
          
            
              
                
                  <a href="https://mech.ubc.ca/antony-hodgson/" target="_blank">Hodgson, Antony J</a>,
                
              
            
          
        
          
          
          
          
            
              
                
                
          
          
          
            
              
                
                  and <a href="https://bisicl.ece.ubc.ca/rafeef/" target="_blank">Abugharbieh, Rafeef</a>
                
              
            
          
        
      </div>

      <div class="periodical">
      
        <em>In 2015 International Meeting on Computer Assisted Orthopaedic Surgery (CAOS)</em>
      
      
        2015
      
      </div>
    

    <div class="links">
    
    
    
    
      
      <a href="/assets/pdf/CAOS2015.pdf" class="btn btn-sm z-depth-0" role="button" target="_blank">PDF</a>
      
    
    
    
    
    
    
    
    </div>

    <!-- Hidden abstract block -->
    
  </div>
</div>
</li>
<li><div class="row">
  <div class="col-sm-2 abbr">
  
    
    <abbr class="badge">MASc Thesis</abbr>
    
  
  </div>

  <div id="hussain2015robust" class="col-sm-8">
    
      <div class="title">Robust Bone Detection in Ultrasound Using Combined Strain Imaging and Envelope Signal Power Detection</div>
      <div class="author">
        
          
          
          
          
          
          
            
              <em>Hussain, Mohammad Arafat</em>
            
          
        
      </div>

      <div class="periodical">
      
      
        2015
      
      </div>
    

    <div class="links">
    
    
    
      <a href="https://open.library.ubc.ca/cIRcle/collections/ubctheses/24/items/1.0166292" class="btn btn-sm z-depth-0" role="button" target="_blank">HTML</a>
    
    
      
      <a href="https://open.library.ubc.ca/media/download/pdf/24/1.0166292/3" class="btn btn-sm z-depth-0" role="button" target="_blank">PDF</a>
      
    
    
    
    
    
    
    
    </div>

    <!-- Hidden abstract block -->
    
  </div>
</div>
</li></ol>

  <h2 class="year">2014</h2>
  <ol class="bibliography"><li><div class="row">
  <div class="col-sm-2 abbr">
  
    
    <abbr class="badge">Ultrasonics</abbr>
    
  
  </div>

  <div id="hussain2014lesion" class="col-sm-8">
    
      <div class="title">Lesion edge preserved direct average strain estimation for ultrasound elasticity imaging</div>
      <div class="author">
        
          
          
          
          
          
          
            
              
                <em>Hussain, Mohammad Arafat</em>,
              
            
          
        
          
          
          
          
          
          
            
              
                
                  Alam, Farzana,
                
              
            
          
        
          
          
          
          
          
          
            
              
                
                  Rupa, Sharmin Akhtar,
                
              
            
          
        
          
          
          
          
          
          
            
              
                
                  Awwal, Rayhana,
                
              
            
          
        
          
          
          
          
          
          
            
              
                
                  Lee, Soo Yeol,
                
              
            
          
        
          
          
          
          
            
              
                
                
          
          
          
            
              
                
                  and <a href="http://khasan.buet.ac.bd/" target="_blank">Hasan, Md Kamrul</a>
                
              
            
          
        
      </div>

      <div class="periodical">
      
        <em>Ultrasonics</em>
      
      
        2014
      
      </div>
    

    <div class="links">
    
      <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a>
    
    
    
      <a href="https://www.sciencedirect.com/science/article/pii/S0041624X13001686?casa_token=BkTjesAnkx8AAAAA:o0nLzpt357pVNIzqqgZyjv9HcAVKDrWhjjYGXTz6DnkTeUrTA6JfvdNg3NqkNgNvhC-0Nm9u" class="btn btn-sm z-depth-0" role="button" target="_blank">HTML</a>
    
    
      
      <a href="/assets/pdf/mah2014a.pdf" class="btn btn-sm z-depth-0" role="button" target="_blank">PDF</a>
      
    
    
    
    
    
    
    
    </div>

    <!-- Hidden abstract block -->
    
    <div class="abstract hidden">
      <p>Elasticity imaging techniques with built-in or regularization-based smoothing feature for ensuring strain continuity are not intelligent enough to prevent distortion or lesion edge blurring while smoothing. This paper proposes a novel approach with built-in lesion edge preservation technique for high quality direct average strain imaging. An edge detection scheme, typically used in diffusion filtering is modified here for lesion edge detection. Based on the extracted edge information, lesion edges are preserved by modifying the strain determining cost function in the direct-average-strain-estimation (DASE) method. The proposed algorithm demonstrates approximately 3.42–4.25 dB improvement in terms of edge-mean-square-error (EMSE) than the other reported regularized or average strain estimation techniques in finite-element-modeling (FEM) simulation with almost no sacrifice in elastographic-signal-to-noise-ratio (SNRe) and elastographic-contrast-to-noise-ratio (CNRe) metrics. The efficacy of the proposed algorithm is also tested for the experimental phantom data and in vivo breast data. The results reveal that the proposed method can generate a high quality strain image delineating the lesion edge more clearly than the other reported strain estimation techniques that have been designed to ensure strain continuity. The computational cost, however, is little higher for the proposed method than the simpler DASE and considerably higher than that of the 2D analytic minimization (AM2D) method.</p>
    </div>
    
  </div>
</div>
</li>
<li><div class="row">
  <div class="col-sm-2 abbr">
  
    
    <abbr class="badge">MICCAI</abbr>
    
  
  </div>

  <div id="hussain2014robust" class="col-sm-8">
    
      <div class="title">Robust bone detection in ultrasound using combined strain imaging and envelope signal power detection</div>
      <div class="author">
        
          
          
          
          
          
          
            
              
                <em>Hussain, Mohammad Arafat</em>,
              
            
          
        
          
          
          
          
            
              
            
          
          
          
            
              
                
                  Hodgson, Antony,
                
              
            
          
        
          
          
          
          
            
              
                
                
          
          
          
            
              
                
                  and <a href="https://bisicl.ece.ubc.ca/rafeef/" target="_blank">Abugharbieh, Rafeef</a>
                
              
            
          
        
      </div>

      <div class="periodical">
      
        <em>In International conference on medical image computing and computer-assisted intervention</em>
      
      
        2014
      
      </div>
    

    <div class="links">
    
      <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a>
    
    
    
      <a href="https://link.springer.com/chapter/10.1007/978-3-319-10404-1_45" class="btn btn-sm z-depth-0" role="button" target="_blank">HTML</a>
    
    
      
      <a href="/assets/pdf/MICCAI2014.pdf" class="btn btn-sm z-depth-0" role="button" target="_blank">PDF</a>
      
    
    
    
    
    
    
    
    </div>

    <!-- Hidden abstract block -->
    
    <div class="abstract hidden">
      <p>Bone localization in ultrasound (US) remains challenging despite encouraging advances. Current methods, e.g. local image phase-based feature analysis, showed promising results but remain reliant on delicate parameter selection processes and prone to errors at confounding soft tissue interfaces of similar appearance to bone interfaces. We propose a different approach combining US strain imaging and envelope power detection at each radio-frequency (RF) sample. After initial estimation of strain and envelope power maps, we modify their dynamic ranges into a modified strain map (MSM) and a modified envelope map (MEM) that we subsequently fuse into a single combined map that we show corresponds robustly to actual bone boundaries. Our quantitative results demonstrate a marked reduction in false positive responses at soft tissue interfaces and an increase in bone delineation accuracy. Comparisons to the state-of-the-art on a finite-element-modelling (FEM) phantom and fiducial-based experimental phantom show an average improvement in mean absolute error (MAE) between actual and estimated bone boundaries of 32% and 14%, respectively. We also demonstrate an average reduction in false bone responses of 87% and 56%, respectively. Finally, we qualitatively validate on clinical in vivo data of the human radius and ulna bones, and demonstrate similar improvements to those observed on phantoms.</p>
    </div>
    
  </div>
</div>
</li></ol>

  <h2 class="year">2013</h2>
  <ol class="bibliography"><li><div class="row">
  <div class="col-sm-2 abbr">
  
    
    <abbr class="badge">IEEE TUFFC</abbr>
    
  
  </div>

  <div id="hasan2013using" class="col-sm-8">
    
      <div class="title">Using nearest neighbors for accurate estimation of ultrasonic attenuation in the spectral domain</div>
      <div class="author">
        
          
          
          
          
            
              
                
                
          
          
          
            
              
                
                  <a href="http://khasan.buet.ac.bd/" target="_blank">Hasan, Md Kamrul</a>,
                
              
            
          
        
          
          
          
          
          
          
            
              
                <em>Hussain, Mohammad Arafat</em>,
              
            
          
        
          
          
          
          
          
          
            
              
                
                  Ara, Sharmin R,
                
              
            
          
        
          
          
          
          
          
          
            
              
                
                  Lee, Soo Yeol,
                
              
            
          
        
          
          
          
          
          
          
            
              
                
                  and Alam, S Kaisar
                
              
            
          
        
      </div>

      <div class="periodical">
      
        <em>IEEE transactions on ultrasonics, ferroelectrics, and frequency control</em>
      
      
        2013
      
      </div>
    

    <div class="links">
    
      <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a>
    
    
    
      <a href="https://ieeexplore.ieee.org/abstract/document/6521059?casa_token=2s5boH1hizUAAAAA:eI8qGb0LDefeIogW6kTDUZ0fV26Yp8l9Z9gOL-G4hJ8VrkrlDKwO4SfH1Fn1vA69zdiooG4" class="btn btn-sm z-depth-0" role="button" target="_blank">HTML</a>
    
    
      
      <a href="/assets/pdf/mah2013a.pdf" class="btn btn-sm z-depth-0" role="button" target="_blank">PDF</a>
      
    
    
    
    
    
    
    
    </div>

    <!-- Hidden abstract block -->
    
    <div class="abstract hidden">
      <p>Attenuation is a key diagnostic parameter of tissue pathology change and thus may play a vital role in the quantitative discrimination of malignant and benign tumors in soft tissue. In this paper, two novel techniques are proposed for estimating the average ultrasonic attenuation in soft tissue using the spectral domain weighted nearest neighbor method. Because the attenuation coefficient of soft tissues can be considered to be a continuous function in a small neighborhood, we directly estimate an average value of it from the slope of the regression line fitted to the 1) modified average midband fit value and 2) the average center frequency shift along the depth. To calculate the average midband fit value, an average regression line computed from the exponentially weighted short-time Fourier transform (STFT) of the neighboring 1-D signal blocks, in the axial and lateral directions, is fitted over the usable bandwidth of the normalized power spectrum. The average center frequency downshift is computed from the maximization of a cost function defined from the normalized spectral cross-correlation (NSCC) of exponentially weighted nearest neighbors in both directions. Different from the large spatial signal-block-based spectral stability approach, a costfunction- based approach incorporating NSCC functions of neighboring 1-D signal blocks is introduced. This paves the way for using comparatively smaller spatial area along the lateral direction, a necessity for producing more realistic attenuation estimates for heterogeneous tissue. For accurate estimation of the attenuation coefficient, we also adopt a reference-phantombased diffraction-correction technique for both methods. The proposed attenuation estimation algorithm demonstrates better performance than other reported techniques in the tissue-mimicking phantom and the in vivo breast data analysis.</p>
    </div>
    
  </div>
</div>
</li>
<li><div class="row">
  <div class="col-sm-2 abbr">
  
    
    <abbr class="badge">MSc Thesis</abbr>
    
  
  </div>

  <div id="hussain2013average" class="col-sm-8">
    
      <div class="title">Average Strain Estimation for Ultrasound Elastography Using Exponentially Weighted Nearest Neighbors</div>
      <div class="author">
        
          
          
          
          
          
          
            
              <em>Hussain, Mohammad Arafat</em>
            
          
        
      </div>

      <div class="periodical">
      
      
        2013
      
      </div>
    

    <div class="links">
    
    
    
      <a href="http://lib.buet.ac.bd:8080/xmlui/handle/123456789/3451" class="btn btn-sm z-depth-0" role="button" target="_blank">HTML</a>
    
    
      
      <a href="http://lib.buet.ac.bd:8080/xmlui/bitstream/handle/123456789/3451/Full%20Thesis.pdf?sequence=1&amp;isAllowed=y" class="btn btn-sm z-depth-0" role="button" target="_blank">PDF</a>
      
    
    
    
    
    
    
    
    </div>

    <!-- Hidden abstract block -->
    
  </div>
</div>
</li></ol>

  <h2 class="year">2012</h2>
  <ol class="bibliography"><li><div class="row">
  <div class="col-sm-2 abbr">
  
    
    <abbr class="badge">IEEE TUFFC</abbr>
    
  
  </div>

  <div id="hussain2012direct" class="col-sm-8">
    
      <div class="title">Direct and gradient-based average strain estimation by using weighted nearest neighbor cross-correlation peaks</div>
      <div class="author">
        
          
          
          
          
          
          
            
              
                <em>Hussain, Mohammad Arafat</em>,
              
            
          
        
          
          
          
          
          
          
            
              
                
                  Anas, Emran Mohammad Abu,
                
              
            
          
        
          
          
          
          
          
          
            
              
                
                  Alam, S Kaisar,
                
              
            
          
        
          
          
          
          
          
          
            
              
                
                  Lee, Soo Yeol,
                
              
            
          
        
          
          
          
          
            
              
                
                
          
          
          
            
              
                
                  and <a href="http://khasan.buet.ac.bd/" target="_blank">Hasan, Md Kamrul</a>
                
              
            
          
        
      </div>

      <div class="periodical">
      
        <em>IEEE transactions on ultrasonics, ferroelectrics, and frequency control</em>
      
      
        2012
      
      </div>
    

    <div class="links">
    
      <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a>
    
    
    
      <a href="https://ieeexplore.ieee.org/abstract/document/6264135?casa_token=PIy45Ng4P0IAAAAA:oJcEziPV396ApM43mXRcCpUXmXhcqplWD-qOn4xAwO0OR3KPAr7V45m_YOU3z-AzQ82qyhg" class="btn btn-sm z-depth-0" role="button" target="_blank">HTML</a>
    
    
      
      <a href="/assets/pdf/mah2012a.pdf" class="btn btn-sm z-depth-0" role="button" target="_blank">PDF</a>
      
    
    
    
    
    
    
    
    </div>

    <!-- Hidden abstract block -->
    
    <div class="abstract hidden">
      <p>In this paper, two novel approaches, gradientbased and direct strain estimation techniques, are proposed for high-quality average strain imaging incorporating a cost function maximization. Stiffness typically is a continuous function. Consequently, stiffness of proximal tissues is very close to that of the tissue corresponding to a given data window. Hence, a cost function is defined from exponentially weighted neighboring pre- and post-compression RF echo normalized cross-correlation peaks in the lateral (for displacement estimation) or in both the axial and the lateral (for direct strain estimation) directions. This enforces a controlled continuity in displacement/strain and average displacement/strain is calculated from the corresponding maximized cost function. Axial stress causes lateral shift in the tissue. Therefore, a 1-D post-compression echo segment is selected by incorporating Poisson’s ratio. Two stretching factors are considered simultaneously in gradient-based strain estimation that allow imaging the lesions properly. The proposed time-domain gradient-based and direct-strain-estimation-based algorithms demonstrate significantly better performance in terms of elastographic signal-to-noise ratio (SNRe), elastographic contrast-to-noise ratio (CNRe), peak signal-to-noise ratio (PSNR), and mean structural similarity (MSSIM) than the other reported time-domain gradientbased and direct-strain-estimation techniques in finite element modeling (FEM) simulation and phantom experiments. For example, in FEM simulation, it has been found that the proposed direct strain estimation method can improve up to approximately 2.49 to 8.71, 2.2 to 6.63, 1.5 to 5, and 1.59 to 2.45 dB in the SNRe, CNRe, PSNR, and MSSIM compared with the traditional direct strain estimation method, respectively, and the proposed gradient-based algorithm demonstrates 2.99 to 16.26, 18.74 to 23.88, 3 to 9.5, and 0.6 to 5.36 dB improvement in the SNRe, CNRe, PSNR, and MSSIM, respectively, compared with a recently reported time-domain gradient-based technique. The range of improvement as noted above is for low to high applied strains. In addition, the comparative results using the in vivo breast data (including malignant or benign masses) also show that the lesion size is better defined by the proposed gradient-based average strain estimation technique.</p>
    </div>
    
  </div>
</div>
</li>
<li><div class="row">
  <div class="col-sm-2 abbr">
  
    
    <abbr class="badge">Ultras. Imag.</abbr>
    
  
  </div>

  <div id="hussain2012robust" class="col-sm-8">
    
      <div class="title">Robust strain-estimation algorithm using combined radiofrequency and envelope cross-correlation with diffusion filtering</div>
      <div class="author">
        
          
          
          
          
          
          
            
              
                <em>Hussain, Mohammad Arafat</em>,
              
            
          
        
          
          
          
          
          
          
            
              
                
                  Alam, S Kaisar,
                
              
            
          
        
          
          
          
          
          
          
            
              
                
                  Lee, Soo Yeol,
                
              
            
          
        
          
          
          
          
            
              
                
                
          
          
          
            
              
                
                  and <a href="http://khasan.buet.ac.bd/" target="_blank">Hasan, Md Kamrul</a>
                
              
            
          
        
      </div>

      <div class="periodical">
      
        <em>Ultrasonic imaging</em>
      
      
        2012
      
      </div>
    

    <div class="links">
    
      <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a>
    
    
    
      <a href="https://journals.sagepub.com/doi/abs/10.1177/016173461203400203?casa_token=BsoXF5galF8AAAAA:a6IOEWbjSXOOFT4xm6HjaWpQp411uUccdJsJLRy9pWZp7LPiJBpH1kxWMXYTztQTIroEIBM4rE0" class="btn btn-sm z-depth-0" role="button" target="_blank">HTML</a>
    
    
      
      <a href="/assets/pdf/mah2012b.pdf" class="btn btn-sm z-depth-0" role="button" target="_blank">PDF</a>
      
    
    
    
    
    
    
    
    </div>

    <!-- Hidden abstract block -->
    
    <div class="abstract hidden">
      <p>In ultrasound elastography, the strain in compressed tissue due to external deformation is estimated and is smaller in harder than softer tissue. With increased stress, the nonaxial motions of tissue elements increase and result in noisier strain images. At high strain, the envelope of the rf signal exhibits robustness to signal decorrelation. However, the precision of strain estimates using envelope signals is much worse compared to that using the rf signals. In this paper, we propose a novel approach for robust strain estimation by combining weighted rf cross-correlation and envelope cross-correlation functions. An applied strain-dependent piecewise-linear-weight is used for this purpose. In addition, we introduce nonlinear diffusion filtering to further enhance the resulting strain image. The results of our algorithm are demonstrated for up to 10% applied strain using a finite-element modelling (FEM) simulation phantom. It reveals that the elastographic signal-to-noise ratio (SNRe) and the elastographic contrast-to-noise ratio (CNRe) of the strain images can be improved more significantly than with other algorithms used in this paper. In addition, comparative results in terms of the mean structural similarity (MSSIM) using in vivo breast data show that the strain image quality can be improved noticeably by the proposed method than with the techniques employed in this work.</p>
    </div>
    
  </div>
</div>
</li>
<li><div class="row">
  <div class="col-sm-2 abbr">
  
    
    <abbr class="badge">ABS-AIUM</abbr>
    
  
  </div>

  <div id="hussain2012improved" class="col-sm-8">
    
      <div class="title">Improved Elasticity Imaging by Maximizing the Weighted Peaks of the Nearest Neighbor Cross-correlation Function</div>
      <div class="author">
        
          
          
          
          
          
          
            
              
                <em>Hussain, Mohammad Arafat</em>,
              
            
          
        
          
          
          
          
          
          
            
              
                
                  Anas, Emran Mohammad Abu,
                
              
            
          
        
          
          
          
          
          
          
            
              
                
                  Alam, S Kaisar,
                
              
            
          
        
          
          
          
          
          
          
            
              
                
                  Lee, Soo Yeol,
                
              
            
          
        
          
          
          
          
            
              
                
                
          
          
          
            
              
                
                  and <a href="http://khasan.buet.ac.bd/" target="_blank">Hasan, Md Kamrul</a>
                
              
            
          
        
      </div>

      <div class="periodical">
      
        <em>In 2012 American Institution of Ultrasound in Medicine (AIUM) Annual Convention and Preconvention Program</em>
      
      
        2012
      
      </div>
    

    <div class="links">
    
    
    
    
    
    
    
    
    
      
      <a href="/assets/pdf/mah2012c.pdf" class="btn btn-sm z-depth-0" role="button" target="_blank">Slides</a>
      
    
    
    </div>

    <!-- Hidden abstract block -->
    
  </div>
</div>
</li>
<li><div class="row">
  <div class="col-sm-2 abbr">
  
    
    <abbr class="badge">ABS-UITS</abbr>
    
  
  </div>

  <div id="hussain2012robusu" class="col-sm-8">
    
      <div class="title">A Robust Strain Estimation Algorithm Using Combined Radio-frequency and Envelope Cross-correlation</div>
      <div class="author">
        
          
          
          
          
          
          
            
              
                <em>Hussain, Mohammad Arafat</em>,
              
            
          
        
          
          
          
          
          
          
            
              
                
                  Alam, S Kaisar,
                
              
            
          
        
          
          
          
          
          
          
            
              
                
                  Lee, Soo Yeol,
                
              
            
          
        
          
          
          
          
            
              
                
                
          
          
          
            
              
                
                  and <a href="http://khasan.buet.ac.bd/" target="_blank">Hasan, Md Kamrul</a>
                
              
            
          
        
      </div>

      <div class="periodical">
      
        <em>In Ultrasonic Imaging and Tissue Characterization Symposium</em>
      
      
        2012
      
      </div>
    

    <div class="links">
    
    
    
    
    
    
    
    
    
      
      <a href="/assets/pdf/mah2012d.pdf" class="btn btn-sm z-depth-0" role="button" target="_blank">Slides</a>
      
    
    
    </div>

    <!-- Hidden abstract block -->
    
  </div>
</div>
</li></ol>

  <h2 class="year">2011</h2>
  <ol class="bibliography"><li><div class="row">
  <div class="col-sm-2 abbr">
  
    
    <abbr class="badge">BSc Thesis</abbr>
    
  
  </div>

  <div id="hussain2011ultrasound" class="col-sm-8">
    
      <div class="title">Ultrasound Strain Imaging in Wavelet Domain</div>
      <div class="author">
        
          
          
          
          
          
          
            
              
                
                  Islam, Md Tauhidul*,
                
              
            
          
        
          
          
          
          
          
          
            
              
                and <em>Hussain, Mohammad Arafat*</em>
              
            
          
        
      </div>

      <div class="periodical">
      
      
        2011
      
      </div>
    

    <div class="links">
    
    
    
    
      
      <a href="https://app.box.com/s/5ia82d9nu3wbscz9nmfyeys1rifx7bu3" class="btn btn-sm z-depth-0" role="button" target="_blank">PDF</a>
      
    
    
    
    
    
    
    
    </div>

    <!-- Hidden abstract block -->
    
  </div>
</div>
</li></ol>

  <h2 class="year">2010</h2>
  <ol class="bibliography"><li><div class="row">
  <div class="col-sm-2 abbr">
  
    
    <abbr class="badge">UKSim</abbr>
    
  
  </div>

  <div id="kabir2010non" class="col-sm-8">
    
      <div class="title">Non-linear down-sampling and signal reconstruction, without folding</div>
      <div class="author">
        
          
          
          
          
          
          
            
              
                
                  Kabir, Hussain Mohammed Dipu,
                
              
            
          
        
          
          
          
          
          
          
            
              
                
                  Alam, Syed Bahauddin,
                
              
            
          
        
          
          
          
          
          
          
            
              
                
                  Azam, Md Isme,
                
              
            
          
        
          
          
          
          
          
          
            
              
                <em>Hussain, Mohammad Arafat</em>,
              
            
          
        
          
          
          
          
          
          
            
              
                
                  Sazzad, ABM Rafi,
                
              
            
          
        
          
          
          
          
          
          
            
              
                
                  Sakib, Md Nazmus,
                
              
            
          
        
          
          
          
          
          
          
            
              
                
                  and Matin, Md Abdul
                
              
            
          
        
      </div>

      <div class="periodical">
      
        <em>In 2010 Fourth UKSim European Symposium on Computer Modeling and Simulation</em>
      
      
        2010
      
      </div>
    

    <div class="links">
    
      <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a>
    
    
    
      <a href="https://ieeexplore.ieee.org/abstract/document/5703672?casa_token=88mmjYne1iMAAAAA:9yQ6oJc_GOmZWNwEJcjLgM4zjCOe6eXiflpaxh3KwwamTd1v804e8-ETEK5IzAWFxzUEGsc" class="btn btn-sm z-depth-0" role="button" target="_blank">HTML</a>
    
    
      
      <a href="/assets/pdf/mah2010.pdf" class="btn btn-sm z-depth-0" role="button" target="_blank">PDF</a>
      
    
    
    
    
    
    
    
    </div>

    <!-- Hidden abstract block -->
    
    <div class="abstract hidden">
      <p>This paper presents a theory of 1.5 factor nonlinear down-sampling, reconstruction and noise elimination. For linear down sampling of two or three factor, one sample is taken and next one or two samples are not taken/discarded. Here in non-linear down sampling two or three samples are taken and the next one is not taken. The purpose of this nonlinear down sampling is to send less data samples in voice communication. Though one sample is discarded after taking two samples value of this sample can be reconstructed from values of other samples. Here, two samples are at original sampling period, T s interval and next two samples are at 2T s interval. High-frequency sharp changes were extracted when sampled at T s interval. From received signal, discarded sample can be reconstructed from nearby four samples (Previous two and next two). When original signal contains higher frequency some error signal is introduced, after reconstruction. This error signal depends on original signal. Error signal is eliminated using original signal. Down-sampling is performed after sampling and signal reconstruction is performed just before hearing the sound.</p>
    </div>
    
  </div>
</div>
</li></ol>


</div>

  </article>

</div>

    </div>

    <!-- Footer -->

    
<footer class="fixed-bottom">
  <div class="container mt-0">
    &copy; Copyright 2021 M. Arafat  Hussain, PhD.
    
    
    
  </div>
</footer>



  </body>

  <!-- Bootsrap & MDB scripts -->
<script src="https://cdnjs.cloudflare.com/ajax/libs/popper.js/2.4.4/umd/popper.min.js" integrity="sha512-eUQ9hGdLjBjY3F41CScH3UX+4JDSI9zXeroz7hJ+RteoCaY+GP/LDoM8AO+Pt+DRFw3nXqsjh9Zsts8hnYv8/A==" crossorigin="anonymous"></script>
<script src="https://stackpath.bootstrapcdn.com/bootstrap/4.5.2/js/bootstrap.min.js" integrity="sha512-M5KW3ztuIICmVIhjSqXe01oV2bpe248gOxqmlcYrEzAvws7Pw3z6BK0iGbrwvdrUQUhi3eXgtxp5I8PDo9YfjQ==" crossorigin="anonymous"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/mdbootstrap/4.19.1/js/mdb.min.js" integrity="sha512-Mug9KHKmroQFMLm93zGrjhibM2z2Obg9l6qFG2qKjXEXkMp/VDkI4uju9m4QKPjWSwQ6O2qzZEnJDEeCw0Blcw==" crossorigin="anonymous"></script>

  
<!-- Mansory & imagesLoaded -->
<script defer src="https://unpkg.com/masonry-layout@4/dist/masonry.pkgd.min.js"></script>
<script defer src="https://unpkg.com/imagesloaded@4/imagesloaded.pkgd.min.js"></script>
<script defer src="/assets/js/mansory.js" type="text/javascript"></script>


  
<!-- Enable Tooltips -->
<script type="text/javascript">
$(function () {$('[data-toggle="tooltip"]').tooltip()})
</script>



<!-- Load Common JS -->
<script src="/assets/js/common.js"></script>


</html>
