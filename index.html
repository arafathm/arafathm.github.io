<!DOCTYPE html>
<html>

  <head>
    <meta charset="utf-8">
<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<meta http-equiv="X-UA-Compatible" content="IE=edge">

<title>M. Arafat  Hussain, PhD</title>
<meta name="description" content="">

<!-- Open Graph -->


<!-- Bootstrap & MDB -->
<link href="https://stackpath.bootstrapcdn.com/bootstrap/4.5.2/css/bootstrap.min.css" rel="stylesheet" integrity="sha512-MoRNloxbStBcD8z3M/2BmnT+rg4IsMxPkXaGh2zD6LGNNFE80W3onsAhRcMAMrSoyWL9xD7Ert0men7vR8LUZg==" crossorigin="anonymous">
<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/mdbootstrap/4.19.1/css/mdb.min.css" integrity="sha512-RO38pBRxYH3SoOprtPTD86JFOclM51/XTIdEPh5j8sj4tp8jmQIx26twG52UaLi//hQldfrh7e51WzP9wuP32Q==" crossorigin="anonymous" />

<!-- Fonts & Icons -->
<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.14.0/css/all.min.css"  integrity="sha512-1PKOgIY59xJ8Co8+NE6FZ+LOAZKjy+KY8iq0G4B3CyeY6wYHN3yt9PW0XpSriVlkMXe40PTKnXrLnZ9+fkDaog==" crossorigin="anonymous">
<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/academicons/1.9.0/css/academicons.min.css" integrity="sha512-W4yqoT1+8NLkinBLBZko+dFB2ZbHsYLDdr50VElllRcNt2Q4/GSs6u71UHKxB7S6JEMCp5Ve4xjh3eGQl/HRvg==" crossorigin="anonymous">
<link rel="stylesheet" type="text/css" href="https://fonts.googleapis.com/css?family=Roboto:300,400,500,700|Roboto+Slab:100,300,400,500,700|Material+Icons">

<!-- Code Syntax Highlighting -->
<link rel="stylesheet" href="https://gitcdn.xyz/repo/jwarby/jekyll-pygments-themes/master/github.css" />

<!-- Styles -->

<link rel="icon" href="data:image/svg+xml,<svg xmlns=%22http://www.w3.org/2000/svg%22 viewBox=%220 0 100 100%22><text y=%22.9em%22 font-size=%2290%22>Ⓜ️</text></svg>">

<link rel="stylesheet" href="/assets/css/main.css">

<link rel="canonical" href="/">

<!-- JQuery -->
<!-- jQuery -->
<script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.5.1/jquery.min.js" integrity="sha512-bLT0Qm9VnAYZDflyKcBaQ2gg0hSYNQrJ8RilYldYQ1FxQYoCLtUjuuRuZo+fjqhx/qtq/1itJ0C2ejDxltZVFg==" crossorigin="anonymous"></script>


<!-- Theming-->






    
<!-- MathJax -->
<script type="text/javascript">
  window.MathJax = {
    tex: {
      tags: 'ams'
    }
  };
</script>
<script defer type="text/javascript" id="MathJax-script" src="https://cdn.jsdelivr.net/npm/mathjax@3.1.2/es5/tex-mml-chtml.js"></script>
<script defer src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>


  </head>

  <body class="fixed-top-nav ">

    <!-- Header -->

    <header>

    <!-- Nav Bar -->
    <nav id="navbar" class="navbar navbar-light navbar-expand-sm fixed-top">
    <div class="container">
      
        <!-- Social Icons -->
        <div class="navbar-brand social">
          <a href="mailto:%6D%6F%68%61%6D%6D%61%64.%68%75%73%73%61%69%6E@%63%68%69%6C%64%72%65%6E%73.%68%61%72%76%61%72%64.%65%64%75"><i class="fas fa-envelope"></i></a>
<a href="https://orcid.org/0000-0003-0545-5779" target="_blank" title="ORCID"><i class="ai ai-orcid"></i></a>
<a href="https://scholar.google.com/citations?user=https://scholar.google.ca/citations?user=hFwvdQcAAAAJ&hl=en" target="_blank" title="Google Scholar"><i class="ai ai-google-scholar"></i></a>


<a href="https://github.com/marafathussain" target="_blank" title="GitHub"><i class="fab fa-github"></i></a>
<a href="https://www.linkedin.com/in/mohammad-arafat-hussain" target="_blank" title="LinkedIn"><i class="fab fa-linkedin"></i></a>










        </div>
      
      <!-- Navbar Toggle -->
      <button class="navbar-toggler collapsed ml-auto" type="button" data-toggle="collapse" data-target="#navbarNav" aria-controls="navbarNav" aria-expanded="false" aria-label="Toggle navigation">
        <span class="sr-only">Toggle navigation</span>
        <span class="icon-bar top-bar"></span>
        <span class="icon-bar middle-bar"></span>
        <span class="icon-bar bottom-bar"></span>
      </button>
      <div class="collapse navbar-collapse text-right" id="navbarNav">
        <ul class="navbar-nav ml-auto flex-nowrap">
          <!-- About -->
          <li class="nav-item active">
            <a class="nav-link" href="/">
              about
              
                <span class="sr-only">(current)</span>
              
            </a>
          </li>
          
          <!-- Other pages -->
          
          
          
          
          
          
          
          
          
          
          
          
          
          <li class="nav-item ">
              <a class="nav-link" href="/cv/">
                cv
                
              </a>
          </li>
          
          
          
          <li class="nav-item ">
              <a class="nav-link" href="/publications/">
                publications
                
              </a>
          </li>
          
          
          
          <li class="nav-item ">
              <a class="nav-link" href="/research/">
                research
                
              </a>
          </li>
          
          
          
          <li class="nav-item ">
              <a class="nav-link" href="/teaching/">
                teaching
                
              </a>
          </li>
          
          
          
        </ul>
      </div>
    </div>
  </nav>

</header>


    <!-- Content -->

    <div class="container mt-5">
      <div class="post">

  <header class="post-header">
    <h1 class="post-title">
     <span class="font-weight-bold">M. Arafat</span>  Hussain, PhD
    </h1>
     <p class="desc"><b>Research Fellow, Harvard Medical School, Boston Children's Hospital</b></p>
  </header>

  <article>
    
    <div class="profile float-right">
      
        <img class="img-fluid z-depth-1 rounded" src="/assets/img/img_new.png">
      
      
        <div class="address">
          <!-- <p>555 your office number</p>
 <p>123 your address street</p>
 <p>Your City, State 12345</p> -->

        </div>
      
    </div>
    

    <div class="clearfix">
      <p>I am currently a Postdoctoral Research Fellow in the <a href="https://projects.iq.harvard.edu/i3-lab" target="_blank">Image, Informatics &amp; Intelligence (i3) Research Lab</a> of <a href="https://scholar.harvard.edu/yangming.ou" target="_blank">Prof. Yangming Ou</a> at Harvard Medical School, Boston, Massachusetts. My research interests lie in machine/deep learning and its application to medical image analysis.</p>

<p>Previously, I worked as a Postdoctoral Research Associate in the <a href="https://www.medicalimageanalysis.com/" target="_blank">Medical Image Analysis Lab (MIAL)</a> of <a href="https://www.sfu.ca/computing/people/faculty/ghassanhamarneh.html" target="_blank">Prof. Ghassan Hamarneh</a> at <a href="https://www.sfu.ca/computing.html" target="_blank">Simon Fraser University</a>, Burnaby, BC, Canada.</p>

<p>I completed my Ph.D. in Biomedical Engineering under the supervision of <a href="https://bisicl.ece.ubc.ca/rafeef/" target="_blank">Prof. Rafeef Garbi</a> at the <a href="https://bisicl.ece.ubc.ca/" target="_blank">University of British Columbia (UBC)</a>, Vancouver. In my Ph.D. project, I primarily focused on kidney cancer detection and analysis in CT using deep learning. I also completed my M.A.Sc. in Biomedical Engineering under the supervision of Prof. Rafeef Garbi and <a href="https://mech.ubc.ca/antony-hodgson/" target="_blank">Prof. Antony Hodgson</a> at UBC, Vancouver. My M.A.Sc. project focused on robust bone boundary localization in ultrasound to facilitate minimally invasive ultrasound-guided orthopedic surgery.</p>

<p>Before joining UBC, I completed M.Sc. and B.Sc. in Electrical and Electronic Engineering at <a href="https://www.buet.ac.bd/web/" target="_blank">Bangladesh University of Engineering &amp; Technology (BUET)</a>. During my M.Sc., I worked as a Research Engineer under the supervision of <a href="http://khasan.buet.ac.bd/" target="_blank">Prof. Md Kamrul Hasan</a>, and developed novel ultrasound elastography techniques for breast cancer detection. I also worked as a Software Engineer in the <a href="https://research.samsung.com/srbd" target="_blank">Samsung R&amp;D Institute Bangladesh</a> after completing my B.Sc. degree.</p>

    </div>

    
      <div class="news">
  <h2>news</h2>
  
    <div class="table-responsive">
      <table class="table table-sm table-borderless">
      
      
        <tr>
          <th scope="row">Aug 2, 2021</th>
          <td>
            
              Paper accepted in Computers in Biology and Medicine.

            
          </td>
        </tr>
      
        <tr>
          <th scope="row">Apr 16, 2021</th>
          <td>
            
              Paper accepted in Computerized Medical Imaging and Graphics.

            
          </td>
        </tr>
      
        <tr>
          <th scope="row">Jan 5, 2021</th>
          <td>
            
              Paper accepted in IEEE Transaction on Medical Imaging.

            
          </td>
        </tr>
      
        <tr>
          <th scope="row">Oct 22, 2020</th>
          <td>
            
              Invited talk at the UBC <a href="https://www.bme.ubc.ca/events/event/sbme-virtual-seminar-hussain/">SBME</a> virtual seminar.

            
          </td>
        </tr>
      
        <tr>
          <th scope="row">Mar 11, 2020</th>
          <td>
            
              Defended Ph.D. thesis at UBC, Vancouver, and Started PostDoc in <a href="https://www.medicalimageanalysis.com/">MIAL</a> at <a href="https://www.sfu.ca/computing.html">SFU</a>.

            
          </td>
        </tr>
      
        <tr>
          <th scope="row">Nov 22, 2019</th>
          <td>
            
              Invited talk at the <a href="https://www.camca.mgh.harvard.edu/">CAMCA</a>, Harvard University.

            
          </td>
        </tr>
      
        <tr>
          <th scope="row">Oct 24, 2019</th>
          <td>
            
              Invited talk at the <a href="https://dbpeds.stanford.edu/">DBPEDS</a>, Stanford University.

            
          </td>
        </tr>
      
      </table>
    </div>
  
</div>

    

    
      <div class="publications">
  <h2>selected publications</h2>
  <ol class="bibliography"><li><div class="row">
  <div class="col-sm-2 abbr">
  
    
    <abbr class="badge">CIBM</abbr>
    
  
  </div>

  <div id="momeny2021learning" class="col-sm-8">
    
      <div class="title">Learning-to-Augment Strategy using Noisy and Denoised Data: Improving Generalizability of Deep CNN for the Detection of COVID-19 in X-ray Images</div>
      <div class="author">
        
          
          
          
          
          
          
            
              
                
                  Momeny, Mohammad,
                
              
            
          
        
          
          
          
          
          
          
            
              
                
                  Neshat, Ali Asghar,
                
              
            
          
        
          
          
          
          
          
          
            
              
                <em>Hussain, Mohammad Arafat</em>,
              
            
          
        
          
          
          
          
          
          
            
              
                
                  Kia, Solmaz,
                
              
            
          
        
          
          
          
          
          
          
            
              
                
                  Marhamati, Mahmoud,
                
              
            
          
        
          
          
          
          
          
          
            
              
                
                  Jahanbakhshi, Ahmad,
                
              
            
          
        
          
          
          
          
            
              
                
                
          
          
          
            
              
                
                  and <a href="https://www.sfu.ca/computing/people/faculty/ghassanhamarneh.html" target="_blank">Hamarneh, Ghassan</a>
                
              
            
          
        
      </div>

      <div class="periodical">
      
        <em>Computers in Biology and Medicine</em>
      
      
        2021
      
      </div>
    

    <div class="links">
    
      <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a>
    
    
    
      <a href="https://www.sciencedirect.com/science/article/abs/pii/S0010482521004984" class="btn btn-sm z-depth-0" role="button" target="_blank">HTML</a>
    
    
      
      <a href="/assets/pdf/cibm2021.pdf" class="btn btn-sm z-depth-0" role="button" target="_blank">PDF</a>
      
    
    
    
    
      <a href="https://github.com/mohamadmomeny/Learning-to-augment-strategy" class="btn btn-sm z-depth-0" role="button" target="_blank">Code</a>
    
    
    
    
    </div>

    <!-- Hidden abstract block -->
    
    <div class="abstract hidden">
      <p>Chest X-ray images are used in deep convolutional neural networks for the detection of COVID-19, the greatest human challenge of the 21st century. Robustness to noise and improvement of generalization are the major challenges in designing these networks. In this paper, we introduce a strategy for data augmentation using the determination of the type and value of noise density to improve the robustness and generalization of deep CNNs for COVID-19 detection. Firstly, we present a learning-to-augment approach that generates new noisy variants of the original image data with optimized noise density. We apply a Bayesian optimization technique to control and choose the optimal noise type and its parameters. Secondly, we propose a novel data augmentation strategy, based on denoised X-ray images, that uses the distance between denoised and original pixels to generate new data. We develop an autoencoder model to create new data using denoised images corrupted by the Gaussian and impulse noise. A database of chest X-ray images, containing COVID-19 positive images, normal images, and other non-COVID pneumonia images, is used to fine-tune the pre-trained networks (AlexNet, ShuffleNet, ResNet18, and GoogleNet). The proposed method has the better performance in comparison with the data augmentation approaches in terms of sensitivity (by 0.808), specificity (by 0.915), and F-Measure (by 0.737).</p>
    </div>
    
  </div>
</div>
</li>
<li><div class="row">
  <div class="col-sm-2 abbr">
  
    
    <abbr class="badge">CMIG</abbr>
    
  
  </div>

  <div id="hussain2021learnable" class="col-sm-8">
    
      <div class="title">Learnable Image Histograms-based Deep Radiomics for Renal Cell Carcinoma Grading and Staging</div>
      <div class="author">
        
          
          
          
          
          
          
            
              
                <em>Hussain, Mohammad Arafat</em>,
              
            
          
        
          
          
          
          
            
              
                
                
          
          
          
            
              
                
                  <a href="https://www.sfu.ca/computing/people/faculty/ghassanhamarneh.html" target="_blank">Hamarneh, Ghassan</a>,
                
              
            
          
        
          
          
          
          
            
              
                
                
          
          
          
            
              
                
                  and <a href="https://bisicl.ece.ubc.ca/rafeef/" target="_blank">Garbi, Rafeef</a>
                
              
            
          
        
      </div>

      <div class="periodical">
      
        <em>Computerized Medical Imaging and Graphics</em>
      
      
        2021
      
      </div>
    

    <div class="links">
    
      <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a>
    
    
    
      <a href="https://www.sciencedirect.com/science/article/abs/pii/S0895611121000732" class="btn btn-sm z-depth-0" role="button" target="_blank">HTML</a>
    
    
      
      <a href="/assets/pdf/cmig_arafat_2021.pdf" class="btn btn-sm z-depth-0" role="button" target="_blank">PDF</a>
      
    
    
    
    
      <a href="https://github.com/marafathussain/ImHistNet" class="btn btn-sm z-depth-0" role="button" target="_blank">Code</a>
    
    
    
    
    </div>

    <!-- Hidden abstract block -->
    
    <div class="abstract hidden">
      <p>Fuhrman cancer grading and tumor-node-metastasis (TNM) cancer staging systems are typically used by clinicians in the treatment planning of renal cell carcinoma (RCC), a common cancer in men and women worldwide. Pathologists typically use percutaneous renal biopsy for RCC grading, while staging is performed by volumetric medical image analysis before renal surgery. Recent studies suggest that clinicians can effectively perform these classification tasks non-invasively by analysing image texture features of RCC from computed tomography (CT) data. However, image feature identification for RCC grading and staging often relies on laborious manual processes, which is error prone and time-intensive. To address this challenge, this paper proposes a learnable image histogram in the deep neural network framework that can learn task-specific image histograms with variable bin centers and widths. The proposed approach enables learning statistical context features from raw medical data, which cannot be performed by a conventional convolutional neural network (CNN). The linear basis function of our learnable image histogram is piece-wise differentiable, enabling back-propagating errors to update the variable bin centers and widths during training. This novel approach can segregate the CT textures of an RCC in different intensity spectra, which enables effcient Fuhrman low (I/II) and high (III/IV) grading as well as RCC low (I/II) and high (III/IV) staging. The proposed method is validated on a clinical CT dataset of 159 patients from The Cancer Imaging Archive (TCIA) database, and it demonstrates 80% and 83% accuracy in RCC grading and staging, respectively.</p>
    </div>
    
  </div>
</div>
</li>
<li><div class="row">
  <div class="col-sm-2 abbr">
  
    
    <abbr class="badge">IEEE TMI</abbr>
    
  
  </div>

  <div id="hussain2021cascaded" class="col-sm-8">
    
      <div class="title">Cascaded Localization Regression Neural Nets for Kidney Localization and Segmentation-free Volume Estimation</div>
      <div class="author">
        
          
          
          
          
          
          
            
              
                <em>Hussain, Mohammad Arafat</em>,
              
            
          
        
          
          
          
          
            
              
                
                
          
          
          
            
              
                
                  <a href="https://www.sfu.ca/computing/people/faculty/ghassanhamarneh.html" target="_blank">Hamarneh, Ghassan</a>,
                
              
            
          
        
          
          
          
          
            
              
                
                
          
          
          
            
              
                
                  and <a href="https://bisicl.ece.ubc.ca/rafeef/" target="_blank">Garbi, Rafeef</a>
                
              
            
          
        
      </div>

      <div class="periodical">
      
        <em>IEEE Transactions on Medical Imaging</em>
      
      
        2021
      
      </div>
    

    <div class="links">
    
      <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a>
    
    
    
      <a href="https://ieeexplore.ieee.org/abstract/document/9358223?casa_token=rxZNi4GaP-YAAAAA:vlaAvOf6J1pKBT9goM4k0cCgPyJQ9NgOg_SSzt4iAFwHINOSelv-LsPXU44-XYmkME_wsI8" class="btn btn-sm z-depth-0" role="button" target="_blank">HTML</a>
    
    
      
      <a href="/assets/pdf/tmi2021.pdf" class="btn btn-sm z-depth-0" role="button" target="_blank">PDF</a>
      
    
    
    
    
    
    
    
    </div>

    <!-- Hidden abstract block -->
    
    <div class="abstract hidden">
      <p>Kidney volume is an essential biomarker for a number of kidney disease diagnoses, for example, chronic kidney disease. Existing total kidney volume estimation methods often rely on an intermediate kidney segmentation step. On the other hand, automatic kidney localization in volumetric medical images is a critical step that often precedes subsequent data processing and analysis. Most current approaches perform kidney localization via an intermediate classification or regression step. This paper proposes an integrated deep learning approach for (i) kidney localization in computed tomography scans and (ii) segmentation-free renal volume estimation. Our localization method uses a selection-convolutional neural network that approximates the kidney inferior-superior span along the axial direction. Cross-sectional (2D) slices from the estimated span are subsequently used in a combined sagittal-axial Mask-RCNN that detects the organ bounding boxes on the axial and sagittal slices, the combination of which produces a final 3D organ bounding box. Furthermore, we use a fully convolutional network to estimate the kidney volume that skips the segmentation procedure. We also present a mathematical expression to approximate the ‘volume error’ metric from the ‘Sørensen–Dice coefficient.’ We accessed 100 patients’ CT scans from the Vancouver General Hospital records and obtained 210 patients’ CT scans from the 2019 Kidney Tumor Segmentation Challenge database to validate our method. Our method produces a kidney boundary wall localization error of  2.4mm and a mean volume estimation error of  5%.</p>
    </div>
    
  </div>
</div>
</li>
<li><div class="row">
  <div class="col-sm-2 abbr">
  
    
    <abbr class="badge">MICCAI</abbr>
    
  
  </div>

  <div id="hussain2019imhistnet" class="col-sm-8">
    
      <div class="title">ImHistNet: Learnable image histogram based DNN with application to noninvasive determination of carcinoma grades in CT scans</div>
      <div class="author">
        
          
          
          
          
          
          
            
              
                <em>Hussain, Mohammad Arafat</em>,
              
            
          
        
          
          
          
          
            
              
                
                
          
          
          
            
              
                
                  <a href="https://www.sfu.ca/computing/people/faculty/ghassanhamarneh.html" target="_blank">Hamarneh, Ghassan</a>,
                
              
            
          
        
          
          
          
          
            
              
                
                
          
          
          
            
              
                
                  and <a href="https://bisicl.ece.ubc.ca/rafeef/" target="_blank">Garbi, Rafeef</a>
                
              
            
          
        
      </div>

      <div class="periodical">
      
        <em>In International Conference on Medical Image Computing and Computer-Assisted Intervention</em>
      
      
        2019
      
      </div>
    

    <div class="links">
    
      <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a>
    
    
    
      <a href="https://link.springer.com/chapter/10.1007/978-3-030-32226-7_15" class="btn btn-sm z-depth-0" role="button" target="_blank">HTML</a>
    
    
      
      <a href="/assets/pdf/mahmiccai19.pdf" class="btn btn-sm z-depth-0" role="button" target="_blank">PDF</a>
      
    
    
    
    
      <a href="https://github.com/marafathussain/ImHistNet" class="btn btn-sm z-depth-0" role="button" target="_blank">Code</a>
    
    
    
    
    </div>

    <!-- Hidden abstract block -->
    
    <div class="abstract hidden">
      <p>Renal cell carcinoma (RCC) is the seventh most common cancer worldwide, accounting for an estimated 140,000 global deaths annually. Clear cell RCC (ccRCC) is the major subtype of RCC and its biological aggressiveness affects prognosis and treatment planning. An important ccRCC prognostic predictor is its ‘grade’ for which the 4-tiered Fuhrman grading system is used. Although the Fuhrman grade can be identified by percutaneous renal biopsy, recent studies suggested that such grades may be non-invasively identified by studying image texture features of the ccRCC from computed tomography (CT) data. Such image feature based identification currently mostly relies on laborious manual processes based on visual inspection of 2D image slices that are time-consuming and subjective. In this paper, we propose a learnable image histogram based deep neural network approach that can perform the Fuhrman low (I/II) and high (III/IV) grade classification for ccRCC in CT scans. Validated on a clinical CT dataset of 159 patients from the TCIA database, our method classified ccRCC low and high grades with 80% accuracy and 85% AUC.</p>
    </div>
    
  </div>
</div>
</li>
<li><div class="row">
  <div class="col-sm-2 abbr">
  
    
    <abbr class="badge">MICCAI-MLMI</abbr>
    
  
  </div>

  <div id="hussain2019renal" class="col-sm-8">
    
      <div class="title">Renal Cell Carcinoma Staging with Learnable Image Histogram-Based Deep Neural Network</div>
      <div class="author">
        
          
          
          
          
          
          
            
              
                <em>Hussain, Mohammad Arafat</em>,
              
            
          
        
          
          
          
          
            
              
                
                
          
          
          
            
              
                
                  <a href="https://www.sfu.ca/computing/people/faculty/ghassanhamarneh.html" target="_blank">Hamarneh, Ghassan</a>,
                
              
            
          
        
          
          
          
          
            
              
                
                
          
          
          
            
              
                
                  and <a href="https://bisicl.ece.ubc.ca/rafeef/" target="_blank">Garbi, Rafeef</a>
                
              
            
          
        
      </div>

      <div class="periodical">
      
        <em>In International Workshop on Machine Learning in Medical Imaging</em>
      
      
        2019
      
      </div>
    

    <div class="links">
    
      <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a>
    
    
    
      <a href="https://link.springer.com/chapter/10.1007/978-3-030-32692-0_61" class="btn btn-sm z-depth-0" role="button" target="_blank">HTML</a>
    
    
      
      <a href="/assets/pdf/mahmlmi19.pdf" class="btn btn-sm z-depth-0" role="button" target="_blank">PDF</a>
      
    
    
    
    
      <a href="https://github.com/marafathussain/ImHistNet" class="btn btn-sm z-depth-0" role="button" target="_blank">Code</a>
    
    
    
    
    </div>

    <!-- Hidden abstract block -->
    
    <div class="abstract hidden">
      <p>Renal cell carcinoma (RCC) is the seventh most common cancer worldwide, accounting for an estimated 140,000 global deaths annually. An important RCC prognostic predictor is its ‘stage’ for which the tumor-node-metastasis (TNM) staging system is used. Although TNM staging is performed by radiologists via pre-surgery volumetric medical image analysis, a recent study suggested that such staging may be performed by studying the image features of the RCC from computed tomography (CT) data. Currently TNM staging mostly relies on laborious manual processes based on visual inspection of 2D CT image slices that are time-consuming and subjective; a recent study reported about   ∼ 25% misclassification in their patient pools. Recently, we proposed a learnable image histogram based deep neural network approach (ImHistNet) for RCC grading, which is capable of learning textural features directly from the CT images. In this paper, using a similar architecture, we perform the stage low (I/II) and high (III/IV) classification for RCC in CT scans. Validated on a clinical CT dataset of 159 patients from the TCIA database, our method classified RCC low and high stages with about 83% accuracy.</p>
    </div>
    
  </div>
</div>
</li>
<li><div class="row">
  <div class="col-sm-2 abbr">
  
    
    <abbr class="badge">MICCAI</abbr>
    
  
  </div>

  <div id="hussain2018noninvasive" class="col-sm-8">
    
      <div class="title">Noninvasive determination of gene mutations in clear cell renal cell carcinoma using multiple instance decisions aggregated CNN</div>
      <div class="author">
        
          
          
          
          
          
          
            
              
                <em>Hussain, Mohammad Arafat</em>,
              
            
          
        
          
          
          
          
            
              
                
                
          
          
          
            
              
                
                  <a href="https://www.sfu.ca/computing/people/faculty/ghassanhamarneh.html" target="_blank">Hamarneh, Ghassan</a>,
                
              
            
          
        
          
          
          
          
            
              
                
                
          
          
          
            
              
                
                  and <a href="https://bisicl.ece.ubc.ca/rafeef/" target="_blank">Garbi, Rafeef</a>
                
              
            
          
        
      </div>

      <div class="periodical">
      
        <em>In International Conference on Medical Image Computing and Computer-Assisted Intervention</em>
      
      
        2018
      
      </div>
    

    <div class="links">
    
      <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a>
    
    
    
      <a href="https://link.springer.com/chapter/10.1007/978-3-030-00934-2_73" class="btn btn-sm z-depth-0" role="button" target="_blank">HTML</a>
    
    
      
      <a href="/assets/pdf/Arafat_MICCAI18.pdf" class="btn btn-sm z-depth-0" role="button" target="_blank">PDF</a>
      
    
    
    
    
    
    
    
    </div>

    <!-- Hidden abstract block -->
    
    <div class="abstract hidden">
      <p>Kidney clear cell renal cell carcinoma (ccRCC) is the major sub-type of RCC, constituting one the most common cancers worldwide accounting for a steadily increasing mortality rate with 350,000 new cases recorded in 2012. Understanding the underlying genetic mutations in ccRCC provides crucial information enabling malignancy staging and patient survival estimation thus plays a vital role in accurate ccRCC diagnosis, prognosis, treatment planning, and response assessment. Although the underlying gene mutations can be identified by whole genome sequencing of the ccRCC following invasive nephrectomy or kidney biopsy procedures, recent studies have suggested that such mutations may be noninvasively identified by studying image features of the ccRCC from Computed Tomography (CT) data. Such image feature identification currently relies on laborious manual processes based on visual inspection of 2D image slices that are time-consuming and subjective. In this paper, we propose a convolutional neural network approach for automatic detection of underlying ccRCC gene mutations from 3D CT volumes. We aggregate the mutation-presence/absence decisions for all the ccRCC slices in a kidney into a robust singular decision that determines whether the interrogated kidney bears a specific mutation or not. When validated on clinical CT datasets of 267 patients from the TCIA database, our method detected gene mutations with 94% accuracy.</p>
    </div>
    
  </div>
</div>
</li>
<li><div class="row">
  <div class="col-sm-2 abbr">
  
    
    <abbr class="badge">MICCAI</abbr>
    
  
  </div>

  <div id="hussain2017segmentation" class="col-sm-8">
    
      <div class="title">Segmentation-free kidney localization and volume estimation using aggregated orthogonal decision CNNs</div>
      <div class="author">
        
          
          
          
          
          
          
            
              
                <em>Hussain, Mohammad Arafat</em>,
              
            
          
        
          
          
          
          
          
          
            
              
                
                  Amir-Khalili, Alborz,
                
              
            
          
        
          
          
          
          
            
              
                
                
          
          
          
            
              
                
                  <a href="https://www.sfu.ca/computing/people/faculty/ghassanhamarneh.html" target="_blank">Hamarneh, Ghassan</a>,
                
              
            
          
        
          
          
          
          
            
              
                
                
          
          
          
            
              
                
                  and <a href="https://bisicl.ece.ubc.ca/rafeef/" target="_blank">Abugharbieh, Rafeef</a>
                
              
            
          
        
      </div>

      <div class="periodical">
      
        <em>In International Conference on Medical Image Computing and Computer-Assisted Intervention</em>
      
      
        2017
      
      </div>
    

    <div class="links">
    
      <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a>
    
    
    
      <a href="https://link.springer.com/chapter/10.1007/978-3-319-66179-7_70" class="btn btn-sm z-depth-0" role="button" target="_blank">HTML</a>
    
    
      
      <a href="/assets/pdf/Arafat_MICCAI17.pdf" class="btn btn-sm z-depth-0" role="button" target="_blank">PDF</a>
      
    
    
    
    
    
    
    
    </div>

    <!-- Hidden abstract block -->
    
    <div class="abstract hidden">
      <p>Kidney volume is an important bio-marker in the clinical diagnosis of various renal diseases. For example, it plays an essential role in follow-up evaluation of kidney transplants. Most existing methods for volume estimation rely on kidney segmentation as a prerequisite step, which has various limitations such as initialization-sensitivity and computationally-expensive optimization. In this paper, we propose a hybrid localization-volume estimation deep learning approach capable of (i) localizing kidneys in abdominal CT images, and (ii) estimating renal volume without requiring segmentation. Our approach involves multiple levels of self-learning of image representation using convolutional neural layers, which we show better capture the rich and complex variability in kidney data, demonstrably outperforming hand-crafted feature representations. We validate our method on clinical data of 100 patients with a total of 200 kidney samples (left and right). Our results demonstrate a 55% increase in kidney boundary localization accuracy, and a 30% increase in volume estimation accuracy compared to recent state-of-the-art methods deploying regression-forest-based learning for the same tasks.</p>
    </div>
    
  </div>
</div>
</li>
<li><div class="row">
  <div class="col-sm-2 abbr">
  
    
    <abbr class="badge">MICCAI-MLMI</abbr>
    
  
  </div>

  <div id="hussain2017collage" class="col-sm-8">
    
      <div class="title">Collage CNN for renal cell carcinoma detection from CT</div>
      <div class="author">
        
          
          
          
          
          
          
            
              
                <em>Hussain, Mohammad Arafat</em>,
              
            
          
        
          
          
          
          
          
          
            
              
                
                  Amir-Khalili, Alborz,
                
              
            
          
        
          
          
          
          
            
              
                
                
          
          
          
            
              
                
                  <a href="https://www.sfu.ca/computing/people/faculty/ghassanhamarneh.html" target="_blank">Hamarneh, Ghassan</a>,
                
              
            
          
        
          
          
          
          
            
              
                
                
          
          
          
            
              
                
                  and <a href="https://bisicl.ece.ubc.ca/rafeef/" target="_blank">Abugharbieh, Rafeef</a>
                
              
            
          
        
      </div>

      <div class="periodical">
      
        <em>In International Workshop on Machine Learning in Medical Imaging</em>
      
      
        2017
      
      </div>
    

    <div class="links">
    
      <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a>
    
    
    
      <a href="https://link.springer.com/chapter/10.1007/978-3-319-67389-9_27" class="btn btn-sm z-depth-0" role="button" target="_blank">HTML</a>
    
    
      
      <a href="/assets/pdf/Arafat_MLMI17.pdf" class="btn btn-sm z-depth-0" role="button" target="_blank">PDF</a>
      
    
    
    
    
    
    
    
    </div>

    <!-- Hidden abstract block -->
    
    <div class="abstract hidden">
      <p>Renal cell carcinoma (RCC) is a common malignancy that accounts for a steadily increasing mortality rate worldwide. Widespread use of abdominal imaging in recent years, mainly CT and MRI, has significantly increased the detection rates of such cancers. However, detection still relies on a laborious manual process based on visual inspection of 2D image slices. In this paper, we propose an image collage based deep convolutional neural network (CNN) approach for automatic detection of pathological kidneys containing RCC. Our collage approach overcomes the absence of slice-wise training labels, enables slice-reshuffling based data augmentation, and offers favourable training time and performance compared to 3D CNNs. When validated on clinical CT datasets of 160 patients from the TCIA database, our method classified RCC cases vs. normal kidneys with 98% accuracy.</p>
    </div>
    
  </div>
</div>
</li>
<li><div class="row">
  <div class="col-sm-2 abbr">
  
    
    <abbr class="badge">MICCAI-MLMI</abbr>
    
  
  </div>

  <div id="hussain2016segmentation" class="col-sm-8">
    
      <div class="title">Segmentation-free estimation of kidney volumes in CT with dual regression forests</div>
      <div class="author">
        
          
          
          
          
          
          
            
              
                <em>Hussain, Mohammad Arafat</em>,
              
            
          
        
          
          
          
          
            
              
                
                
          
          
          
            
              
                
                  <a href="https://www.sfu.ca/computing/people/faculty/ghassanhamarneh.html" target="_blank">Hamarneh, Ghassan</a>,
                
              
            
          
        
          
          
          
          
          
          
            
              
                
                  O’Connell, Timothy W,
                
              
            
          
        
          
          
          
          
          
          
            
              
                
                  Mohammed, Mohammed F,
                
              
            
          
        
          
          
          
          
            
              
                
                
          
          
          
            
              
                
                  and <a href="https://bisicl.ece.ubc.ca/rafeef/" target="_blank">Abugharbieh, Rafeef</a>
                
              
            
          
        
      </div>

      <div class="periodical">
      
        <em>In International Workshop on Machine Learning in Medical Imaging</em>
      
      
        2016
      
      </div>
    

    <div class="links">
    
      <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a>
    
    
    
      <a href="https://link.springer.com/chapter/10.1007/978-3-319-47157-0_19" class="btn btn-sm z-depth-0" role="button" target="_blank">HTML</a>
    
    
      
      <a href="/assets/pdf/MLMI2016.pdf" class="btn btn-sm z-depth-0" role="button" target="_blank">PDF</a>
      
    
    
    
    
    
    
    
    </div>

    <!-- Hidden abstract block -->
    
    <div class="abstract hidden">
      <p>Accurate estimation of kidney volume is essential for clinical diagnoses and therapeutic decisions related to renal diseases. Existing kidney volume estimation methods rely on an intermediate segmentation step that is subject to various limitations. In this work, we propose a segmentation-free, supervised learning approach that addresses the challenges of accurate kidney volume estimation caused by extensive variations in kidney shape, size and orientation across subjects. We develop dual regression forests to simultaneously predict the kidney area per image slice, and kidney span per image volume. We validate our method on a dataset of 45 subjects with a total of 90 kidney samples. We obtained a volume estimation accuracy higher than existing segmentation-free (by 72 %) and segmentation-based methods (by 82 %). Compared to a single regression model, the dual regression reduced the false positive area-estimates and improved volume estimation accuracy by 41 %. We also found a mean deviation of under 10 % between our estimated kidney volumes and those obtained manually by expert radiologists.</p>
    </div>
    
  </div>
</div>
</li></ol>
</div>

    

    
  </article>

</div>

    </div>

    <!-- Footer -->

    
<footer class="fixed-bottom">
  <div class="container mt-0">
    &copy; Copyright 2021 M. Arafat  Hussain, PhD.
    
    
    
  </div>
</footer>



  </body>

  <!-- Bootsrap & MDB scripts -->
<script src="https://cdnjs.cloudflare.com/ajax/libs/popper.js/2.4.4/umd/popper.min.js" integrity="sha512-eUQ9hGdLjBjY3F41CScH3UX+4JDSI9zXeroz7hJ+RteoCaY+GP/LDoM8AO+Pt+DRFw3nXqsjh9Zsts8hnYv8/A==" crossorigin="anonymous"></script>
<script src="https://stackpath.bootstrapcdn.com/bootstrap/4.5.2/js/bootstrap.min.js" integrity="sha512-M5KW3ztuIICmVIhjSqXe01oV2bpe248gOxqmlcYrEzAvws7Pw3z6BK0iGbrwvdrUQUhi3eXgtxp5I8PDo9YfjQ==" crossorigin="anonymous"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/mdbootstrap/4.19.1/js/mdb.min.js" integrity="sha512-Mug9KHKmroQFMLm93zGrjhibM2z2Obg9l6qFG2qKjXEXkMp/VDkI4uju9m4QKPjWSwQ6O2qzZEnJDEeCw0Blcw==" crossorigin="anonymous"></script>

  
<!-- Mansory & imagesLoaded -->
<script defer src="https://unpkg.com/masonry-layout@4/dist/masonry.pkgd.min.js"></script>
<script defer src="https://unpkg.com/imagesloaded@4/imagesloaded.pkgd.min.js"></script>
<script defer src="/assets/js/mansory.js" type="text/javascript"></script>


  
<!-- Enable Tooltips -->
<script type="text/javascript">
$(function () {$('[data-toggle="tooltip"]').tooltip()})
</script>



<!-- Load Common JS -->
<script src="/assets/js/common.js"></script>


</html>
